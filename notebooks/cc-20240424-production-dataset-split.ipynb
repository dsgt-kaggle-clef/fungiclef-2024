{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/chris/fungiclef-2024/.venv/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from fungiclef.utils import get_spark, spark_resource, read_config\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = read_config(path='../fungiclef/config.json')\n",
    "\n",
    "# First, we read the metadata for the dataset and make a proper new one. This will be the single source of truth we use to build the rest of our stuff on\n",
    "# This corresponds to the DF20 dataset\n",
    "TRAIN_METADATA = config[\"gs_paths\"][\"train\"][\"metadata\"]\n",
    "\n",
    "# These two correspond to the DF21 dataset\n",
    "VALID_METADATA = config[\"gs_paths\"][\"val\"][\"metadata\"]\n",
    "TEST_METADATA = config[\"gs_paths\"][\"test\"][\"metadata\"]\n",
    "\n",
    "PRODUCTION_BUCKET = 'gs://dsgt-clef-fungiclef-2024/production/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Making a new train / valid / test set split with metadata file\n",
    "\n",
    "The motivation to this is to make a proper, bigger training set, where unknown classes are also included in the dataset. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_metadata_df = pd.read_csv(TRAIN_METADATA)\n",
    "valid_metadata_df = pd.read_csv(VALID_METADATA)\n",
    "test_metadata_df = pd.read_csv(TEST_METADATA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/04/24 12:06:00 WARN SparkSession: Using an existing Spark session; only runtime SQL configurations will take effect.\n"
     ]
    }
   ],
   "source": [
    "# \n",
    "full_dataset_pq = config[\"gs_paths\"][\"train_and_test_300px_corrected\"][\"raw_parquet\"]\n",
    "spark = get_spark(**{\n",
    "    \"spark.sql.parquet.enableVectorizedReader\": False, \n",
    "})\n",
    "\n",
    "full_dataset_df = spark.read.parquet(full_dataset_pq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "observation_ids = full_dataset_df.select(\"observationID\").toPandas()['observationID']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "available images:  356770\n"
     ]
    }
   ],
   "source": [
    "print(\"available images: \", len(observation_ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train:  295938\n",
      "valid:  60832\n",
      "test:  60225\n",
      "train + valid:  356770\n"
     ]
    }
   ],
   "source": [
    "print(\"train: \", len(train_metadata_df.observationID))\n",
    "print(\"valid: \", len(valid_metadata_df.observationID))\n",
    "print(\"test: \", len(test_metadata_df.observationID))\n",
    "\n",
    "# It appears that the only images we have are the train and validation datasets. Only metadata is available for the public test set. As such, we need to be a bit wiser in how we split up the data in that case. \n",
    "print(\"train + valid: \", len(train_metadata_df.observationID) + len(valid_metadata_df.observationID))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given that we don't have as much \"new\" data, but we still want to keep the data and stratified, the most straightforward way is to split the valid set (60,832 cases) three-fold.\n",
    "\n",
    "1/3rd will go to the training set (such that it can learn concepts such as unknown), \n",
    "\n",
    "1/3rd will become the validation set (for model tuning)\n",
    "\n",
    "1/3rd will become the sacred held out test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Here, we stratify the validation dataset by class_id\n",
    "class_df = valid_metadata_df[['observationID', 'class_id']]\n",
    "\n",
    "# I note that the validation set has numerous repeated observation for some reason. \n",
    "class_df = class_df.drop_duplicates()\n",
    "\n",
    "# For rare classes, we want to keep them within the test set only. \n",
    "test_only_class_ids = class_df.class_id.value_counts()[class_df.class_id.value_counts() < 5].index.tolist()\n",
    "\n",
    "class_df = class_df[~class_df.class_id.isin(test_only_class_ids)]\n",
    "additional_train, new_valid_test = train_test_split(class_df, test_size=0.67, stratify=class_df['class_id'])\n",
    "new_valid, new_test = train_test_split(new_valid_test, test_size=0.5, stratify=new_valid_test['class_id'])\n",
    "new_test = pd.concat((new_test, class_df[class_df.class_id.isin(test_only_class_ids)]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "additional train:  19394\n",
      "new valid:  19788\n",
      "new test:  19746\n"
     ]
    }
   ],
   "source": [
    "# These are the new / additional sets\n",
    "print(\"additional train: \", valid_metadata_df.observationID.isin(additional_train.observationID).sum())\n",
    "print(\"new valid: \", valid_metadata_df.observationID.isin(new_valid.observationID).sum())\n",
    "print(\"new test: \", valid_metadata_df.observationID.isin(new_test.observationID).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_metadata_df['dataset'] = \"train\"\n",
    "# Label the old validation metadata df with new tag\n",
    "valid_metadata_df.loc[valid_metadata_df.observationID.isin(additional_train.observationID), 'dataset'] = \"train\"\n",
    "valid_metadata_df.loc[valid_metadata_df.observationID.isin(new_valid.observationID), 'dataset'] = \"valid\"\n",
    "valid_metadata_df.loc[valid_metadata_df.observationID.isin(new_test.observationID), 'dataset'] = \"test\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "# concat the two and save to bucket\n",
    "PRODUCTION_BUCKET = 'gs://dsgt-clef-fungiclef-2024/production/'\n",
    "\n",
    "full_metadata_df = pd.concat((train_metadata_df, valid_metadata_df))\n",
    "full_metadata_df.to_csv(PRODUCTION_BUCKET + \"metadata/DF_combined_metadata_full_raw.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Preprocessing categorical variables\n",
    "The following section we will be preprocessing the dataset with categorical columns\n",
    "We will also save this mapping to use for the public dataset / for any subsequent inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here, we are only keeping columns that are relevant either for training or inference. \n",
    "# This includes all the columns that were present in the public test metadata dataset\n",
    "TEST_DF_COLUMNS = ['observationID', 'month', 'day', 'countryCode', 'locality', 'level0Gid',\n",
    "       'level0Name', 'level1Gid', 'level1Name', 'level2Gid', 'level2Name',\n",
    "       'Substrate', 'Latitude', 'Longitude', 'CoorUncert', 'Habitat',\n",
    "       'image_path', 'filename', 'MetaSubstrate']\n",
    "\n",
    "# As well as the overall classification of the fungi (this could potentially be useful as additional training targets)\n",
    "COLUMNS_TO_KEEP = TEST_DF_COLUMNS + ['scientificName', 'kingdom', 'phylum', 'class', 'order', 'family', 'genus', 'species', 'poisonous', 'class_id', 'dataset']\n",
    "\n",
    "# These are the categorical columns we will need to factorize and generate labels for\n",
    "CATEGORICAL_COLUMNS = ['locality', 'level0Gid', 'level1Gid', 'level2Gid', 'Substrate', 'Habitat', 'MetaSubstrate', 'kingdom', 'phylum', 'class',\n",
    "       'order', 'family', 'genus', 'species']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1964/2934913616.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  selected_metadata_df.sort_values(by=col, ascending=True, inplace=True)\n",
      "/tmp/ipykernel_1964/2934913616.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  selected_metadata_df.loc[:, f\"{col}_text\"] = selected_metadata_df.loc[:, col]\n",
      "/tmp/ipykernel_1964/2934913616.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  selected_metadata_df.sort_values(by=col, ascending=True, inplace=True)\n",
      "/tmp/ipykernel_1964/2934913616.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  selected_metadata_df.loc[:, f\"{col}_text\"] = selected_metadata_df.loc[:, col]\n",
      "/tmp/ipykernel_1964/2934913616.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  selected_metadata_df.sort_values(by=col, ascending=True, inplace=True)\n",
      "/tmp/ipykernel_1964/2934913616.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  selected_metadata_df.loc[:, f\"{col}_text\"] = selected_metadata_df.loc[:, col]\n",
      "/tmp/ipykernel_1964/2934913616.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  selected_metadata_df.sort_values(by=col, ascending=True, inplace=True)\n",
      "/tmp/ipykernel_1964/2934913616.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  selected_metadata_df.loc[:, f\"{col}_text\"] = selected_metadata_df.loc[:, col]\n",
      "/tmp/ipykernel_1964/2934913616.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  selected_metadata_df.sort_values(by=col, ascending=True, inplace=True)\n",
      "/tmp/ipykernel_1964/2934913616.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  selected_metadata_df.loc[:, f\"{col}_text\"] = selected_metadata_df.loc[:, col]\n",
      "/tmp/ipykernel_1964/2934913616.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  selected_metadata_df.sort_values(by=col, ascending=True, inplace=True)\n"
     ]
    }
   ],
   "source": [
    "selected_metadata_df = full_metadata_df[COLUMNS_TO_KEEP]\n",
    "\n",
    "# This is important to save \n",
    "mapping = {}\n",
    "\n",
    "for col in CATEGORICAL_COLUMNS:\n",
    "    selected_metadata_df.sort_values(by=col, ascending=True, inplace=True)\n",
    "    col_numerical, col_mapping = pd.factorize(selected_metadata_df[col], use_na_sentinel=False)\n",
    "    selected_metadata_df.loc[:, f\"{col}_text\"] = selected_metadata_df.loc[:, col]\n",
    "    selected_metadata_df.loc[:, col] = col_numerical\n",
    "    mapping[col] = {v: k for k, v in enumerate(col_mapping)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# It is vital to save all the mapping for the categorical columns for inference later.\n",
    "# P.S. This is saved in /production/metadata. \n",
    "import pickle\n",
    "\n",
    "CATEGORICAL_MAPPING_LOCATION = \"./categorical_columns_mapping.pkl\"\n",
    "\n",
    "pickle.dump(mapping, open(CATEGORICAL_MAPPING_LOCATION, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lastly, it is vital to remap the unknown class from -1 to another positive integer. Otherwise it will be hard to train and harder to debug.\n",
    "import numpy as np\n",
    "\n",
    "UNKNOWN_CLASS = 1604\n",
    "selected_metadata_df['class_id'] = np.where(selected_metadata_df.class_id==-1, UNKNOWN_CLASS, selected_metadata_df.class_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_metadata_df.to_csv(PRODUCTION_BUCKET + \"metadata/DF_combined_metadata_mapped_columns.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Pair up with embeddings\n",
    "Now that we have a single metadata dataframe as our single source of truth, we will match the embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_metadata_df = pd.read_csv(PRODUCTION_BUCKET + \"metadata/DF_combined_metadata_mapped_columns.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>observationID</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>countryCode</th>\n",
       "      <th>locality</th>\n",
       "      <th>level0Gid</th>\n",
       "      <th>level0Name</th>\n",
       "      <th>level1Gid</th>\n",
       "      <th>level1Name</th>\n",
       "      <th>level2Gid</th>\n",
       "      <th>...</th>\n",
       "      <th>Substrate_text</th>\n",
       "      <th>Habitat_text</th>\n",
       "      <th>MetaSubstrate_text</th>\n",
       "      <th>kingdom_text</th>\n",
       "      <th>phylum_text</th>\n",
       "      <th>class_text</th>\n",
       "      <th>order_text</th>\n",
       "      <th>family_text</th>\n",
       "      <th>genus_text</th>\n",
       "      <th>species_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2238506390</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>DK</td>\n",
       "      <td>5179</td>\n",
       "      <td>9</td>\n",
       "      <td>Denmark</td>\n",
       "      <td>28</td>\n",
       "      <td>Hovedstaden</td>\n",
       "      <td>80</td>\n",
       "      <td>...</td>\n",
       "      <td>soil</td>\n",
       "      <td>park/churchyard</td>\n",
       "      <td>jord</td>\n",
       "      <td>Fungi</td>\n",
       "      <td>Basidiomycota</td>\n",
       "      <td>Agaricomycetes</td>\n",
       "      <td>Polyporales</td>\n",
       "      <td>Meruliaceae</td>\n",
       "      <td>Abortiporus</td>\n",
       "      <td>Abortiporus biennis</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2812984326</td>\n",
       "      <td>7.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>DK</td>\n",
       "      <td>6157</td>\n",
       "      <td>9</td>\n",
       "      <td>Denmark</td>\n",
       "      <td>32</td>\n",
       "      <td>Syddanmark</td>\n",
       "      <td>146</td>\n",
       "      <td>...</td>\n",
       "      <td>dead wood (including bark)</td>\n",
       "      <td>lawn</td>\n",
       "      <td>wood</td>\n",
       "      <td>Fungi</td>\n",
       "      <td>Basidiomycota</td>\n",
       "      <td>Agaricomycetes</td>\n",
       "      <td>Polyporales</td>\n",
       "      <td>Meruliaceae</td>\n",
       "      <td>Abortiporus</td>\n",
       "      <td>Abortiporus biennis</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2465026418</td>\n",
       "      <td>11.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>DK</td>\n",
       "      <td>6829</td>\n",
       "      <td>9</td>\n",
       "      <td>Denmark</td>\n",
       "      <td>31</td>\n",
       "      <td>Sjælland</td>\n",
       "      <td>139</td>\n",
       "      <td>...</td>\n",
       "      <td>dead wood (including bark)</td>\n",
       "      <td>Unmanaged deciduous woodland</td>\n",
       "      <td>wood</td>\n",
       "      <td>Fungi</td>\n",
       "      <td>Basidiomycota</td>\n",
       "      <td>Agaricomycetes</td>\n",
       "      <td>Polyporales</td>\n",
       "      <td>Meruliaceae</td>\n",
       "      <td>Abortiporus</td>\n",
       "      <td>Abortiporus biennis</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2812994333</td>\n",
       "      <td>7.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>DK</td>\n",
       "      <td>6145</td>\n",
       "      <td>9</td>\n",
       "      <td>Denmark</td>\n",
       "      <td>32</td>\n",
       "      <td>Syddanmark</td>\n",
       "      <td>146</td>\n",
       "      <td>...</td>\n",
       "      <td>dead wood (including bark)</td>\n",
       "      <td>lawn</td>\n",
       "      <td>wood</td>\n",
       "      <td>Fungi</td>\n",
       "      <td>Basidiomycota</td>\n",
       "      <td>Agaricomycetes</td>\n",
       "      <td>Polyporales</td>\n",
       "      <td>Meruliaceae</td>\n",
       "      <td>Abortiporus</td>\n",
       "      <td>Abortiporus biennis</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2812983332</td>\n",
       "      <td>8.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>DK</td>\n",
       "      <td>6157</td>\n",
       "      <td>9</td>\n",
       "      <td>Denmark</td>\n",
       "      <td>32</td>\n",
       "      <td>Syddanmark</td>\n",
       "      <td>146</td>\n",
       "      <td>...</td>\n",
       "      <td>dead wood (including bark)</td>\n",
       "      <td>lawn</td>\n",
       "      <td>wood</td>\n",
       "      <td>Fungi</td>\n",
       "      <td>Basidiomycota</td>\n",
       "      <td>Agaricomycetes</td>\n",
       "      <td>Polyporales</td>\n",
       "      <td>Meruliaceae</td>\n",
       "      <td>Abortiporus</td>\n",
       "      <td>Abortiporus biennis</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>356765</th>\n",
       "      <td>2238482337</td>\n",
       "      <td>11.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>DK</td>\n",
       "      <td>9621</td>\n",
       "      <td>9</td>\n",
       "      <td>Denmark</td>\n",
       "      <td>29</td>\n",
       "      <td>Midtjylland</td>\n",
       "      <td>98</td>\n",
       "      <td>...</td>\n",
       "      <td>faeces</td>\n",
       "      <td>other habitat</td>\n",
       "      <td>animals</td>\n",
       "      <td>Fungi</td>\n",
       "      <td>Basidiomycota</td>\n",
       "      <td>Agaricomycetes</td>\n",
       "      <td>Agaricales</td>\n",
       "      <td>Tricholomataceae</td>\n",
       "      <td>Clitocybe</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>356766</th>\n",
       "      <td>2237940567</td>\n",
       "      <td>10.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>DK</td>\n",
       "      <td>2012</td>\n",
       "      <td>9</td>\n",
       "      <td>Denmark</td>\n",
       "      <td>29</td>\n",
       "      <td>Midtjylland</td>\n",
       "      <td>111</td>\n",
       "      <td>...</td>\n",
       "      <td>faeces</td>\n",
       "      <td>salt meadow</td>\n",
       "      <td>animals</td>\n",
       "      <td>Fungi</td>\n",
       "      <td>Basidiomycota</td>\n",
       "      <td>Agaricomycetes</td>\n",
       "      <td>Agaricales</td>\n",
       "      <td>Tricholomataceae</td>\n",
       "      <td>Clitocybe</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>356767</th>\n",
       "      <td>2238455560</td>\n",
       "      <td>11.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>DK</td>\n",
       "      <td>1662</td>\n",
       "      <td>9</td>\n",
       "      <td>Denmark</td>\n",
       "      <td>29</td>\n",
       "      <td>Midtjylland</td>\n",
       "      <td>108</td>\n",
       "      <td>...</td>\n",
       "      <td>faeces</td>\n",
       "      <td>salt meadow</td>\n",
       "      <td>animals</td>\n",
       "      <td>Fungi</td>\n",
       "      <td>Basidiomycota</td>\n",
       "      <td>Agaricomycetes</td>\n",
       "      <td>Agaricales</td>\n",
       "      <td>Tricholomataceae</td>\n",
       "      <td>Clitocybe</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>356768</th>\n",
       "      <td>2449442140</td>\n",
       "      <td>11.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>DK</td>\n",
       "      <td>6116</td>\n",
       "      <td>9</td>\n",
       "      <td>Denmark</td>\n",
       "      <td>31</td>\n",
       "      <td>Sjælland</td>\n",
       "      <td>133</td>\n",
       "      <td>...</td>\n",
       "      <td>faeces</td>\n",
       "      <td>Forest bog</td>\n",
       "      <td>animals</td>\n",
       "      <td>Fungi</td>\n",
       "      <td>Basidiomycota</td>\n",
       "      <td>Agaricomycetes</td>\n",
       "      <td>Agaricales</td>\n",
       "      <td>Tricholomataceae</td>\n",
       "      <td>Clitocybe</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>356769</th>\n",
       "      <td>2238127922</td>\n",
       "      <td>11.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>DK</td>\n",
       "      <td>9056</td>\n",
       "      <td>9</td>\n",
       "      <td>Denmark</td>\n",
       "      <td>31</td>\n",
       "      <td>Sjælland</td>\n",
       "      <td>130</td>\n",
       "      <td>...</td>\n",
       "      <td>faeces</td>\n",
       "      <td>meadow</td>\n",
       "      <td>animals</td>\n",
       "      <td>Fungi</td>\n",
       "      <td>Basidiomycota</td>\n",
       "      <td>Agaricomycetes</td>\n",
       "      <td>Agaricales</td>\n",
       "      <td>Tricholomataceae</td>\n",
       "      <td>Clitocybe</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>356770 rows × 44 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        observationID  month   day countryCode  locality  level0Gid  \\\n",
       "0          2238506390    9.0   1.0          DK      5179          9   \n",
       "1          2812984326    7.0   8.0          DK      6157          9   \n",
       "2          2465026418   11.0  19.0          DK      6829          9   \n",
       "3          2812994333    7.0   9.0          DK      6145          9   \n",
       "4          2812983332    8.0  20.0          DK      6157          9   \n",
       "...               ...    ...   ...         ...       ...        ...   \n",
       "356765     2238482337   11.0  23.0          DK      9621          9   \n",
       "356766     2237940567   10.0  26.0          DK      2012          9   \n",
       "356767     2238455560   11.0   7.0          DK      1662          9   \n",
       "356768     2449442140   11.0   3.0          DK      6116          9   \n",
       "356769     2238127922   11.0  14.0          DK      9056          9   \n",
       "\n",
       "       level0Name  level1Gid   level1Name  level2Gid  ...  \\\n",
       "0         Denmark         28  Hovedstaden         80  ...   \n",
       "1         Denmark         32   Syddanmark        146  ...   \n",
       "2         Denmark         31     Sjælland        139  ...   \n",
       "3         Denmark         32   Syddanmark        146  ...   \n",
       "4         Denmark         32   Syddanmark        146  ...   \n",
       "...           ...        ...          ...        ...  ...   \n",
       "356765    Denmark         29  Midtjylland         98  ...   \n",
       "356766    Denmark         29  Midtjylland        111  ...   \n",
       "356767    Denmark         29  Midtjylland        108  ...   \n",
       "356768    Denmark         31     Sjælland        133  ...   \n",
       "356769    Denmark         31     Sjælland        130  ...   \n",
       "\n",
       "                    Substrate_text                  Habitat_text  \\\n",
       "0                             soil               park/churchyard   \n",
       "1       dead wood (including bark)                          lawn   \n",
       "2       dead wood (including bark)  Unmanaged deciduous woodland   \n",
       "3       dead wood (including bark)                          lawn   \n",
       "4       dead wood (including bark)                          lawn   \n",
       "...                            ...                           ...   \n",
       "356765                      faeces                 other habitat   \n",
       "356766                      faeces                   salt meadow   \n",
       "356767                      faeces                   salt meadow   \n",
       "356768                      faeces                    Forest bog   \n",
       "356769                      faeces                        meadow   \n",
       "\n",
       "        MetaSubstrate_text  kingdom_text    phylum_text      class_text  \\\n",
       "0                     jord         Fungi  Basidiomycota  Agaricomycetes   \n",
       "1                     wood         Fungi  Basidiomycota  Agaricomycetes   \n",
       "2                     wood         Fungi  Basidiomycota  Agaricomycetes   \n",
       "3                     wood         Fungi  Basidiomycota  Agaricomycetes   \n",
       "4                     wood         Fungi  Basidiomycota  Agaricomycetes   \n",
       "...                    ...           ...            ...             ...   \n",
       "356765             animals         Fungi  Basidiomycota  Agaricomycetes   \n",
       "356766             animals         Fungi  Basidiomycota  Agaricomycetes   \n",
       "356767             animals         Fungi  Basidiomycota  Agaricomycetes   \n",
       "356768             animals         Fungi  Basidiomycota  Agaricomycetes   \n",
       "356769             animals         Fungi  Basidiomycota  Agaricomycetes   \n",
       "\n",
       "         order_text       family_text   genus_text         species_text  \n",
       "0       Polyporales       Meruliaceae  Abortiporus  Abortiporus biennis  \n",
       "1       Polyporales       Meruliaceae  Abortiporus  Abortiporus biennis  \n",
       "2       Polyporales       Meruliaceae  Abortiporus  Abortiporus biennis  \n",
       "3       Polyporales       Meruliaceae  Abortiporus  Abortiporus biennis  \n",
       "4       Polyporales       Meruliaceae  Abortiporus  Abortiporus biennis  \n",
       "...             ...               ...          ...                  ...  \n",
       "356765   Agaricales  Tricholomataceae    Clitocybe                  NaN  \n",
       "356766   Agaricales  Tricholomataceae    Clitocybe                  NaN  \n",
       "356767   Agaricales  Tricholomataceae    Clitocybe                  NaN  \n",
       "356768   Agaricales  Tricholomataceae    Clitocybe                  NaN  \n",
       "356769   Agaricales  Tricholomataceae    Clitocybe                  NaN  \n",
       "\n",
       "[356770 rows x 44 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selected_metadata_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For pairing up with embeddings, we will use numerical data only so there is less data to load etc\n",
    "numerical_metadata_df = selected_metadata_df.drop([c + \"_text\" for c in CATEGORICAL_COLUMNS], axis=1)\n",
    "numerical_metadata_df = numerical_metadata_df.drop(['filename', 'scientificName', 'countryCode', 'level0Name', 'level1Name', 'level2Name'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_metadata_df['image_path'] = numerical_metadata_df.image_path.apply(lambda x: x.replace(\".JPG\", \".jpg\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "Exception in thread \"main\" java.nio.file.NoSuchFileException: /tmp/tmpbzot30rp/connection9366208419788263865.info\n",
      "\tat java.base/sun.nio.fs.UnixException.translateToIOException(UnixException.java:92)\n",
      "\tat java.base/sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:111)\n",
      "\tat java.base/sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:116)\n",
      "\tat java.base/sun.nio.fs.UnixFileSystemProvider.newByteChannel(UnixFileSystemProvider.java:219)\n",
      "\tat java.base/java.nio.file.Files.newByteChannel(Files.java:371)\n",
      "\tat java.base/java.nio.file.Files.createFile(Files.java:648)\n",
      "\tat java.base/java.nio.file.TempFileHelper.create(TempFileHelper.java:137)\n",
      "\tat java.base/java.nio.file.TempFileHelper.createTempFile(TempFileHelper.java:160)\n",
      "\tat java.base/java.nio.file.Files.createTempFile(Files.java:868)\n",
      "\tat org.apache.spark.api.python.PythonGatewayServer$.main(PythonGatewayServer.scala:54)\n",
      "\tat org.apache.spark.api.python.PythonGatewayServer.main(PythonGatewayServer.scala)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:566)\n",
      "\tat org.apache.spark.deploy.JavaMainApplication.start(SparkApplication.scala:52)\n",
      "\tat org.apache.spark.deploy.SparkSubmit.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:1029)\n",
      "\tat org.apache.spark.deploy.SparkSubmit.doRunMain$1(SparkSubmit.scala:194)\n",
      "\tat org.apache.spark.deploy.SparkSubmit.submit(SparkSubmit.scala:217)\n",
      "\tat org.apache.spark.deploy.SparkSubmit.doSubmit(SparkSubmit.scala:91)\n",
      "\tat org.apache.spark.deploy.SparkSubmit$$anon$2.doSubmit(SparkSubmit.scala:1120)\n",
      "\tat org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:1129)\n",
      "\tat org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)\n",
      "24/04/24 14:26:09 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "24/04/24 14:26:09 WARN SparkConf: Note that spark.local.dir will be overridden by the value set by the cluster manager (via SPARK_LOCAL_DIRS in mesos/standalone/kubernetes and LOCAL_DIRS in YARN).\n",
      "24/04/24 14:26:22 WARN MetricsConfig: Cannot locate configuration: tried hadoop-metrics2-google-hadoop-file-system.properties,hadoop-metrics2.properties\n",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Match resnet embeddings\n",
    "resnet_pq = \"gs://dsgt-clef-fungiclef-2024/data/parquet/DF20_300px_and_DF21_300px_corrected_FULL_SET_embedding/resnet\"\n",
    "spark = get_spark(**{\n",
    "    \"spark.sql.parquet.enableVectorizedReader\": False, \n",
    "})\n",
    "\n",
    "resnet_df = spark.read.parquet(resnet_pq)\n",
    "resnet_embeddings = resnet_df.select(\"image_path\", \"embeddings\").toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Match dataset by image_path\n",
    "resnet_embeddings_full_df = numerical_metadata_df.set_index('image_path').join(resnet_embeddings.set_index('image_path')).reset_index()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_PATH = \"gs://dsgt-clef-fungiclef-2024/production/resnet/\"\n",
    "resnet_embeddings_full_df[resnet_embeddings_full_df.dataset==\"train\"].to_parquet(DATASET_PATH + \"DF_300_train.parquet\")\n",
    "resnet_embeddings_full_df[resnet_embeddings_full_df.dataset==\"valid\"].to_parquet(DATASET_PATH + \"DF_300_valid.parquet\")\n",
    "resnet_embeddings_full_df[resnet_embeddings_full_df.dataset==\"test\"].to_parquet(DATASET_PATH + \"DF_300_test.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/04/24 13:24:29 WARN SparkSession: Using an existing Spark session; only runtime SQL configurations will take effect.\n"
     ]
    }
   ],
   "source": [
    "# Dino embeddings not working out yet because of the bug. TODO: Re-do dino embeddings\n",
    "dino_dct_pq = config[\"gs_paths\"][\"train_and_test_300px_corrected\"][\"train_dct_parquet\"]\n",
    "spark = get_spark(**{\n",
    "    \"spark.sql.parquet.enableVectorizedReader\": False, \n",
    "})\n",
    "\n",
    "dino_dct_df = spark.read.parquet(dino_dct_pq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 7:>                                                          (0 + 4) / 6]\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "dino_embeddings = dino_dct_df.select(\"ImageUniqueID\", \"dct_embedding\").toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['observationID', 'year', 'month', 'day', 'countryCode', 'locality',\n",
       "       'taxonID', 'scientificName', 'kingdom', 'phylum', 'class', 'order',\n",
       "       'family', 'genus', 'specificEpithet', 'taxonRank', 'species',\n",
       "       'level0Gid', 'level0Name', 'level1Gid', 'level1Name', 'level2Gid',\n",
       "       'level2Name', 'ImageUniqueID', 'Substrate', 'rightsHolder', 'Latitude',\n",
       "       'Longitude', 'CoorUncert', 'Habitat', 'image_path', 'class_id',\n",
       "       'MetaSubstrate', 'poisonous', 'dataset'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_metadata_df.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['observationID', 'month', 'day', 'countryCode', 'locality', 'taxonID',\n",
       "       'scientificName', 'kingdom', 'phylum', 'class', 'order', 'family',\n",
       "       'genus', 'specificEpithet', 'taxonRank', 'species', 'level0Gid',\n",
       "       'level0Name', 'level1Gid', 'level1Name', 'level2Gid', 'level2Name',\n",
       "       'Substrate', 'Latitude', 'Longitude', 'CoorUncert', 'Habitat',\n",
       "       'image_path', 'filename', 'MetaSubstrate', 'class_id', 'poisonous',\n",
       "       'dataset'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_metadata_df.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ImageUniqueID</th>\n",
       "      <th>dct_embedding</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>None</td>\n",
       "      <td>[-27465.547, 14178.638, -20135.004, -6432.8823...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2864913416-287345</td>\n",
       "      <td>[-23667.527, 2323.5469, 37456.824, 45126.812, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2383043463-43428</td>\n",
       "      <td>[-30186.223, 2974.5952, 15293.627, 45778.152, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2446759895-197886</td>\n",
       "      <td>[-23543.812, 12889.68, 10386.561, 12623.754, 5...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>None</td>\n",
       "      <td>[-740.4336, 28029.623, -26031.705, -16861.986,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>320876</th>\n",
       "      <td>None</td>\n",
       "      <td>[-26018.09, -9693.551, 10605.984, 25729.992, 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>320877</th>\n",
       "      <td>None</td>\n",
       "      <td>[-32310.83, 9728.084, 4996.2915, 2508.0183, 16...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>320878</th>\n",
       "      <td>None</td>\n",
       "      <td>[-20754.445, 14093.246, 24992.883, 22008.844, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>320879</th>\n",
       "      <td>2238538042-327236</td>\n",
       "      <td>[-10542.917, 30165.953, 11423.545, 2223.7212, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>320880</th>\n",
       "      <td>None</td>\n",
       "      <td>[-12959.178, 5761.344, 25320.176, -2302.5342, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>320881 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            ImageUniqueID                                      dct_embedding\n",
       "0                    None  [-27465.547, 14178.638, -20135.004, -6432.8823...\n",
       "1       2864913416-287345  [-23667.527, 2323.5469, 37456.824, 45126.812, ...\n",
       "2        2383043463-43428  [-30186.223, 2974.5952, 15293.627, 45778.152, ...\n",
       "3       2446759895-197886  [-23543.812, 12889.68, 10386.561, 12623.754, 5...\n",
       "4                    None  [-740.4336, 28029.623, -26031.705, -16861.986,...\n",
       "...                   ...                                                ...\n",
       "320876               None  [-26018.09, -9693.551, 10605.984, 25729.992, 1...\n",
       "320877               None  [-32310.83, 9728.084, 4996.2915, 2508.0183, 16...\n",
       "320878               None  [-20754.445, 14093.246, 24992.883, 22008.844, ...\n",
       "320879  2238538042-327236  [-10542.917, 30165.953, 11423.545, 2223.7212, ...\n",
       "320880               None  [-12959.178, 5761.344, 25320.176, -2302.5342, ...\n",
       "\n",
       "[320881 rows x 2 columns]"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dino_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/04/24 13:55:11 WARN SparkSession: Using an existing Spark session; only runtime SQL configurations will take effect.\n",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Checking we have the correct set\n",
    "df_full_300_pq = \"gs://dsgt-clef-fungiclef-2024/data/parquet/DF20_300px_and_DF21_300px_corrected\"\n",
    "spark = get_spark(**{\n",
    "    \"spark.sql.parquet.enableVectorizedReader\": False, \n",
    "})\n",
    "\n",
    "df_full_300_df = spark.read.parquet(df_full_300_pq)\n",
    "df_full_img_paths = df_full_300_df.select(\"image_path\").toPandas()[\"image_path\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "356770"
      ]
     },
     "execution_count": 220,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_full_img_paths.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
