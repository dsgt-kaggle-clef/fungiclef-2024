{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Description\n",
    "The objective of this notebook is to\n",
    "1. Combine both train / val dataset on the dataset page to make one very big dataset\n",
    "2. For classes that are NOT in the train dataset, label them as unknown \n",
    "3. Convert the images to binary file and add it to the dataframe\n",
    "4. Filter for variables in test set only\n",
    "5. Convert all categorical variables (for both input and output) into numerical variables\n",
    "6. Save everything into a parquet\n",
    "\n",
    "This is built on / should replace the work done on images-to-parquet.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "DF20_train_path = \"../data/FungiCLEF2023_train_metadata_PRODUCTION.csv\" # This is the dev training set page\n",
    "DF21_val_path = \"../data/FungiCLEF2023_val_metadata_PRODUCTION.csv\" # This is the \"validation\" set on the page. We want to use this with additional data for unknown classes\n",
    "public_test_path = \"../data/FungiCLEF2023_public_test_metadata_PRODUCTION.csv\" # Public test set\n",
    "IMG_PATH = \"../data/DF\"\n",
    "\n",
    "DF20_df = pd.read_csv(DF20_train_path)\n",
    "DF21_df = pd.read_csv(DF21_val_path)\n",
    "test_df = pd.read_csv(public_test_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_val_df = pd.concat((DF20_df, DF21_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['observationID', 'month', 'day', 'countryCode', 'locality', 'level0Gid',\n",
       "       'level0Name', 'level1Gid', 'level1Name', 'level2Gid', 'level2Name',\n",
       "       'Substrate', 'Latitude', 'Longitude', 'CoorUncert', 'Habitat',\n",
       "       'image_path', 'filename', 'MetaSubstrate'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# These are the metadata we want to keep to train on and potentially for prediction\n",
    "test_df.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['observationID', 'year', 'month', 'day', 'countryCode', 'locality',\n",
       "       'taxonID', 'scientificName', 'kingdom', 'phylum', 'class', 'order',\n",
       "       'family', 'genus', 'specificEpithet', 'taxonRank', 'species',\n",
       "       'level0Gid', 'level0Name', 'level1Gid', 'level1Name', 'level2Gid',\n",
       "       'level2Name', 'ImageUniqueID', 'Substrate', 'rightsHolder', 'Latitude',\n",
       "       'Longitude', 'CoorUncert', 'Habitat', 'image_path', 'class_id',\n",
       "       'MetaSubstrate', 'poisonous', 'filename'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Additionally, we probably want to include all the phylum, genus, etc. It might be useful for additional training data.\n",
    "train_val_df.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_to_keep = list(test_df.keys()) + ['scientificName', 'kingdom', 'phylum', 'class', 'order', 'family', 'genus', 'species', 'poisonous', 'class_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_val_df = train_val_df[cols_to_keep]\n",
    "train_val_df.class_id.max()\n",
    "\n",
    "import numpy as np\n",
    "DUMMY_DATE = 361\n",
    "train_val_df.loc[:, 'normalized_day'] = ((train_val_df['month'] - 1) * 30 + train_val_df['day']).fillna(DUMMY_DATE).astype(np.int16, copy=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make the unknown class the last class instead of -1\n",
    "max_id = train_val_df.class_id.max()\n",
    "train_val_df.loc[:, \"class_id\"] = train_val_df.class_id.apply(lambda x: max_id + 1 if x < 0 else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "categoricals = ['locality', 'level0Gid', 'level1Gid', 'level2Gid', 'Substrate', 'Habitat', 'MetaSubstrate', 'kingdom', 'phylum', 'class',\n",
    "       'order', 'family', 'genus', 'species']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is important to save \n",
    "mapping = {}\n",
    "\n",
    "for col in categoricals:\n",
    "    train_val_df.sort_values(by=col, ascending=True, inplace=True)\n",
    "    col_numerical, col_mapping = pd.factorize(train_val_df[col], use_na_sentinel=True)\n",
    "    train_val_df.loc[:, f\"{col}_numerical\"] = col_numerical\n",
    "    mapping[col] = {v: k for k, v in enumerate(col_mapping)}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "CATEGORICAL_MAPPING_LOCATION = \"../data/categorical_mapping.pkl\"\n",
    "\n",
    "pickle.dump(mapping, open(CATEGORICAL_MAPPING_LOCATION, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This should be converted to a script for submission - categorical mapping for test_df\n",
    "\n",
    "test_categoricals = ['locality', 'level0Gid', 'level1Gid', 'level2Gid', 'Substrate', 'Habitat', 'MetaSubstrate']\n",
    "mapping = pickle.load(open(CATEGORICAL_MAPPING_LOCATION, 'rb'))\n",
    "\n",
    "for col in test_categoricals:\n",
    "    test_df.loc[:, col+\"_numerical\"] = test_df[col].apply(lambda x: mapping[col].get(x, -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_val_df.to_csv(\"train_val_df.csv\", index=False)\n",
    "train_val_df = pd.read_csv(\"train_val_df.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7135/7135 [00:07<00:00, 924.61it/s] \n",
      "100%|██████████| 7135/7135 [00:11<00:00, 599.90it/s]\n",
      "100%|██████████| 7135/7135 [00:11<00:00, 646.25it/s]\n",
      "100%|██████████| 7135/7135 [00:12<00:00, 594.26it/s]\n",
      "100%|██████████| 7135/7135 [00:10<00:00, 664.30it/s]\n",
      "100%|██████████| 7135/7135 [00:11<00:00, 625.52it/s]\n",
      "100%|██████████| 7135/7135 [00:11<00:00, 625.90it/s]\n",
      "100%|██████████| 7135/7135 [00:11<00:00, 616.47it/s]\n",
      "100%|██████████| 7135/7135 [00:11<00:00, 636.19it/s]\n",
      "100%|██████████| 7135/7135 [00:12<00:00, 563.38it/s]\n",
      "100%|██████████| 7135/7135 [00:10<00:00, 655.24it/s]\n",
      "100%|██████████| 7135/7135 [00:11<00:00, 617.87it/s]\n",
      "100%|██████████| 7135/7135 [00:11<00:00, 609.77it/s]\n",
      "100%|██████████| 7135/7135 [00:11<00:00, 613.79it/s]\n",
      "100%|██████████| 7135/7135 [00:11<00:00, 603.92it/s]\n",
      "100%|██████████| 7135/7135 [00:11<00:00, 605.97it/s]\n",
      "100%|██████████| 7135/7135 [00:11<00:00, 622.08it/s]\n",
      "100%|██████████| 7135/7135 [00:11<00:00, 606.60it/s]\n",
      "100%|██████████| 7135/7135 [00:14<00:00, 479.07it/s]\n",
      "100%|██████████| 7135/7135 [00:13<00:00, 524.59it/s]\n",
      "100%|██████████| 7135/7135 [00:11<00:00, 604.21it/s]\n",
      "100%|██████████| 7135/7135 [00:12<00:00, 561.18it/s]\n",
      "100%|██████████| 7135/7135 [00:12<00:00, 582.57it/s]\n",
      "100%|██████████| 7135/7135 [00:13<00:00, 530.48it/s]\n",
      "100%|██████████| 7135/7135 [00:12<00:00, 562.86it/s]\n",
      "100%|██████████| 7135/7135 [00:12<00:00, 587.31it/s]"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# This keeps on crashing + is super inefficient :( \n",
    "# Spark doesn't work on my local machine either\n",
    "# Need to adapt it with images_to_parquet.py stuff\n",
    "\n",
    "import pyarrow as pa\n",
    "import pyarrow.parquet as pq\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "\n",
    "IMG_DIR = \"../data/DF/\"\n",
    "\n",
    "df_records = train_val_df.to_dict(\"records\")\n",
    "CHUNKS = 50\n",
    "CHUNK_SIZE = len(df_records) // CHUNKS\n",
    "\n",
    "for i in range(CHUNKS):\n",
    "    records = []\n",
    "    if i == CHUNKS - 1: \n",
    "        chunk = df_records[i * CHUNK_SIZE:]\n",
    "    else: \n",
    "        chunk = df_records[i * CHUNK_SIZE:(i+1) *CHUNK_SIZE]\n",
    "    for r in tqdm(chunk):\n",
    "        img_name = r['image_path']\n",
    "        if len(img_name.split(\"-\")[0]) == 10:\n",
    "\n",
    "            image_path = IMG_DIR + img_name.replace(\"JPG\", \"jpg\")\n",
    "        else: \n",
    "            image_path = IMG_DIR + img_name\n",
    "        with Image.open(image_path) as im:\n",
    "            r.update({\n",
    "                \"img_height\": im.height,\n",
    "                \"img_widgth\": im.width,\n",
    "                \"data\": im.tobytes()\n",
    "            })\n",
    "        records.append(r)\n",
    "\n",
    "    full_df = pd.DataFrame(records)\n",
    "\n",
    "    _dataset_chunk = pa.Table.from_pandas(full_df, preserve_index=False)\n",
    "    pq.write_table(_dataset_chunk, f\"../data/DF_300_{i}.parquet\") # TODO: To change endpoints where these parquets are stored. But we're using spark anywayz lmao"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "poisonous_rare = train_val_df[train_val_df.poisonous==1].class_id.value_counts().tail(10).index\n",
    "non_poisonous_rare = train_val_df[train_val_df.poisonous==0].class_id.value_counts().tail(10).index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "rare_df = train_val_df[train_val_df.class_id.isin(poisonous_rare) | train_val_df.class_id.isin(non_poisonous_rare)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "### This is for the dev set only because the full thing keeps on crashing for me :(\n",
    "selected_mushrooms = ['Neoboletus luridiformis (Rostk.) Gelardi, Simonini & Vizzini, 2014',\n",
    "                      'Imleria badia (Fr.) Vizzini, 2014',\n",
    "                      'Amanita muscaria (L.) Lam., 1783',\n",
    "                      'Russula ochroleuca (Pers.) Fr.',\n",
    "                      'Russula nigricans (Bull.) Fr.',\n",
    "                      'Lactarius blennius (Fr.) Fr.'\n",
    "                      ]\n",
    "\n",
    "dev_set = train_val_df.scientificName.isin(selected_mushrooms)\n",
    "\n",
    "dev_df = pd.concat((train_val_df[dev_set], train_val_df[train_val_df.class_id==1604].sample(1000), rare_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in categoricals:\n",
    "    dev_df.sort_values(by=col, ascending=True, inplace=True)\n",
    "    col_numerical, col_mapping = pd.factorize(dev_df[col], use_na_sentinel=True)\n",
    "    dev_df.loc[:, f\"{col}_numerical\"] = col_numerical\n",
    "\n",
    "# Need to do it for class_id too for dev set\n",
    "dev_df.sort_values(by=\"class_id\", ascending=True, inplace=True)\n",
    "numerical, mapping = pd.factorize(dev_df.class_id)\n",
    "dev_df.loc[:, f\"class_id\"] = numerical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "class_id\n",
       "26    1000\n",
       "0      959\n",
       "12     938\n",
       "9      925\n",
       "22     709\n",
       "10     648\n",
       "21     567\n",
       "3      178\n",
       "6       75\n",
       "20      74\n",
       "2       71\n",
       "18      66\n",
       "4       60\n",
       "13      57\n",
       "11      44\n",
       "23      37\n",
       "1       31\n",
       "15      31\n",
       "16      31\n",
       "17      31\n",
       "19      31\n",
       "8       31\n",
       "7       31\n",
       "5       31\n",
       "24      31\n",
       "25      31\n",
       "14      31\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Number of cases per class\n",
    "dev_df.class_id.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/6749 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6749/6749 [00:08<00:00, 786.11it/s]\n"
     ]
    }
   ],
   "source": [
    "# This keeps on crashing + is super inefficient :( \n",
    "# Spark doesn't work on my local machine either\n",
    "# Need to adapt it with images_to_parquet.py stuff\n",
    "\n",
    "import pyarrow as pa\n",
    "import pyarrow.parquet as pq\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "\n",
    "IMG_DIR = \"../data/DF/\"\n",
    "\n",
    "df_records = dev_df.to_dict(\"records\")\n",
    "\n",
    "records = []\n",
    "\n",
    "for r in tqdm(df_records):\n",
    "    img_name = r['image_path']\n",
    "    if len(img_name.split(\"-\")[0]) == 10:\n",
    "\n",
    "        image_path = IMG_DIR + img_name.replace(\"JPG\", \"jpg\")\n",
    "    else: \n",
    "        image_path = IMG_DIR + img_name\n",
    "    with Image.open(image_path) as im:\n",
    "        r.update({\n",
    "            \"img_height\": im.height,\n",
    "            \"img_widgth\": im.width,\n",
    "            \"data\": im.tobytes()\n",
    "        })\n",
    "    records.append(r)\n",
    "\n",
    "full_df = pd.DataFrame(records)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>observationID</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>countryCode</th>\n",
       "      <th>locality</th>\n",
       "      <th>level0Gid</th>\n",
       "      <th>level0Name</th>\n",
       "      <th>level1Gid</th>\n",
       "      <th>level1Name</th>\n",
       "      <th>level2Gid</th>\n",
       "      <th>...</th>\n",
       "      <th>kingdom_numerical</th>\n",
       "      <th>phylum_numerical</th>\n",
       "      <th>class_numerical</th>\n",
       "      <th>order_numerical</th>\n",
       "      <th>family_numerical</th>\n",
       "      <th>genus_numerical</th>\n",
       "      <th>species_numerical</th>\n",
       "      <th>img_height</th>\n",
       "      <th>img_widgth</th>\n",
       "      <th>data</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2238437186</td>\n",
       "      <td>9.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>DK</td>\n",
       "      <td>Rebæk Sø</td>\n",
       "      <td>DNK</td>\n",
       "      <td>Denmark</td>\n",
       "      <td>DNK.1_1</td>\n",
       "      <td>Hovedstaden</td>\n",
       "      <td>DNK.1.23_1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>200</td>\n",
       "      <td>300</td>\n",
       "      <td>b'\\x9b\\x8e\\x85\\x9b\\x8e\\x85\\x9c\\x8f\\x86\\x9c\\x8f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2425493335</td>\n",
       "      <td>10.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>DK</td>\n",
       "      <td>Færgelunden</td>\n",
       "      <td>DNK</td>\n",
       "      <td>Denmark</td>\n",
       "      <td>DNK.1_1</td>\n",
       "      <td>Hovedstaden</td>\n",
       "      <td>DNK.1.11_1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>360</td>\n",
       "      <td>300</td>\n",
       "      <td>b',3\\x127A\\x1f&gt;L(ET-HT.&gt;D\"36\\x195:#HZDZ|cIz](^...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2868472485</td>\n",
       "      <td>10.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>DK</td>\n",
       "      <td>Store Hareskov</td>\n",
       "      <td>DNK</td>\n",
       "      <td>Denmark</td>\n",
       "      <td>DNK.1_1</td>\n",
       "      <td>Hovedstaden</td>\n",
       "      <td>DNK.1.12_1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>225</td>\n",
       "      <td>300</td>\n",
       "      <td>b'O[GbkXip`|\\x80roqfwzq\\xa2\\xa7\\xa0\\x8c\\x96\\x8...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2238345070</td>\n",
       "      <td>9.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>DK</td>\n",
       "      <td>Rødding</td>\n",
       "      <td>DNK</td>\n",
       "      <td>Denmark</td>\n",
       "      <td>DNK.5_1</td>\n",
       "      <td>Syddanmark</td>\n",
       "      <td>DNK.5.21_1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>300</td>\n",
       "      <td>300</td>\n",
       "      <td>b'\\x15\\x12\\x1b\\x12\\x0c\\x16\\x12\\x0c\\x16\\x1a\\x12...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2427872788</td>\n",
       "      <td>10.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>SE</td>\n",
       "      <td>Hedegärde</td>\n",
       "      <td>SWE</td>\n",
       "      <td>Sweden</td>\n",
       "      <td>SWE.21_1</td>\n",
       "      <td>Västra Götaland</td>\n",
       "      <td>SWE.21.5_1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>300</td>\n",
       "      <td>300</td>\n",
       "      <td>b']qoBUS#64\\x1e.-$0.\\x18\"!\\x0b\\x14\\x11\\x10\\x16...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6744</th>\n",
       "      <td>3126949303</td>\n",
       "      <td>5.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>DK</td>\n",
       "      <td>Lemvig</td>\n",
       "      <td>DNK</td>\n",
       "      <td>Denmark</td>\n",
       "      <td>DNK.2_1</td>\n",
       "      <td>Midtjylland</td>\n",
       "      <td>DNK.2.8_1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>51</td>\n",
       "      <td>78</td>\n",
       "      <td>164</td>\n",
       "      <td>266</td>\n",
       "      <td>225</td>\n",
       "      <td>300</td>\n",
       "      <td>b'\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6745</th>\n",
       "      <td>3052833407</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>DK</td>\n",
       "      <td>Rugård Gods</td>\n",
       "      <td>DNK</td>\n",
       "      <td>Denmark</td>\n",
       "      <td>DNK.2_1</td>\n",
       "      <td>Midtjylland</td>\n",
       "      <td>DNK.2.18_1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>51</td>\n",
       "      <td>78</td>\n",
       "      <td>164</td>\n",
       "      <td>266</td>\n",
       "      <td>240</td>\n",
       "      <td>300</td>\n",
       "      <td>b'\\xe8\\xfd\\xec\\xe9\\xfe\\xed\\xec\\xfe\\xee\\xed\\xff...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6746</th>\n",
       "      <td>3358350449</td>\n",
       "      <td>9.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>DK</td>\n",
       "      <td>Velling Kalv (inkl Velling Gavl)</td>\n",
       "      <td>DNK</td>\n",
       "      <td>Denmark</td>\n",
       "      <td>DNK.2_1</td>\n",
       "      <td>Midtjylland</td>\n",
       "      <td>DNK.2.14_1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>45</td>\n",
       "      <td>101</td>\n",
       "      <td>163</td>\n",
       "      <td>265</td>\n",
       "      <td>169</td>\n",
       "      <td>300</td>\n",
       "      <td>b'\\x1a\\x1d\\x08 #\\x0e#&amp;\\x11 #\\x0e\\x1c\\x1f\\n\\x19...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6747</th>\n",
       "      <td>3412520375</td>\n",
       "      <td>11.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>DK</td>\n",
       "      <td>Mågekolonien</td>\n",
       "      <td>DNK</td>\n",
       "      <td>Denmark</td>\n",
       "      <td>DNK.5_1</td>\n",
       "      <td>Syddanmark</td>\n",
       "      <td>DNK.5.7_1</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>14</td>\n",
       "      <td>50</td>\n",
       "      <td>111</td>\n",
       "      <td>161</td>\n",
       "      <td>262</td>\n",
       "      <td>200</td>\n",
       "      <td>300</td>\n",
       "      <td>b'\\x11\\r\\x04!\\x18\\x0f\\x16\\x0c\\x02\\r\\x00\\x00\\'\\...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6748</th>\n",
       "      <td>3052832315</td>\n",
       "      <td>2.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>DK</td>\n",
       "      <td>Korselitse Mellemskov</td>\n",
       "      <td>DNK</td>\n",
       "      <td>Denmark</td>\n",
       "      <td>DNK.4_1</td>\n",
       "      <td>Sjælland</td>\n",
       "      <td>DNK.4.3_1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>32</td>\n",
       "      <td>130</td>\n",
       "      <td>312</td>\n",
       "      <td>485</td>\n",
       "      <td>400</td>\n",
       "      <td>300</td>\n",
       "      <td>b'!Ku!Ku!Ku!Ku Jt\"It\"Ir\"Ir\\x1fFo\"Gq\"Gq!Gn\"Ho$J...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6749 rows × 47 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      observationID  month   day countryCode  \\\n",
       "0        2238437186    9.0  11.0          DK   \n",
       "1        2425493335   10.0   8.0          DK   \n",
       "2        2868472485   10.0   3.0          DK   \n",
       "3        2238345070    9.0  27.0          DK   \n",
       "4        2427872788   10.0  17.0          SE   \n",
       "...             ...    ...   ...         ...   \n",
       "6744     3126949303    5.0  28.0          DK   \n",
       "6745     3052833407    3.0   2.0          DK   \n",
       "6746     3358350449    9.0  24.0          DK   \n",
       "6747     3412520375   11.0  20.0          DK   \n",
       "6748     3052832315    2.0  21.0          DK   \n",
       "\n",
       "                              locality level0Gid level0Name level1Gid  \\\n",
       "0                             Rebæk Sø       DNK    Denmark   DNK.1_1   \n",
       "1                          Færgelunden       DNK    Denmark   DNK.1_1   \n",
       "2                       Store Hareskov       DNK    Denmark   DNK.1_1   \n",
       "3                              Rødding       DNK    Denmark   DNK.5_1   \n",
       "4                            Hedegärde       SWE     Sweden  SWE.21_1   \n",
       "...                                ...       ...        ...       ...   \n",
       "6744                            Lemvig       DNK    Denmark   DNK.2_1   \n",
       "6745                       Rugård Gods       DNK    Denmark   DNK.2_1   \n",
       "6746  Velling Kalv (inkl Velling Gavl)       DNK    Denmark   DNK.2_1   \n",
       "6747                      Mågekolonien       DNK    Denmark   DNK.5_1   \n",
       "6748             Korselitse Mellemskov       DNK    Denmark   DNK.4_1   \n",
       "\n",
       "           level1Name   level2Gid  ... kingdom_numerical phylum_numerical  \\\n",
       "0         Hovedstaden  DNK.1.23_1  ...                 1                1   \n",
       "1         Hovedstaden  DNK.1.11_1  ...                 1                1   \n",
       "2         Hovedstaden  DNK.1.12_1  ...                 1                1   \n",
       "3          Syddanmark  DNK.5.21_1  ...                 1                1   \n",
       "4     Västra Götaland  SWE.21.5_1  ...                 1                1   \n",
       "...               ...         ...  ...               ...              ...   \n",
       "6744      Midtjylland   DNK.2.8_1  ...                 1                0   \n",
       "6745      Midtjylland  DNK.2.18_1  ...                 1                0   \n",
       "6746      Midtjylland  DNK.2.14_1  ...                 1                0   \n",
       "6747       Syddanmark   DNK.5.7_1  ...                 2                4   \n",
       "6748         Sjælland   DNK.4.3_1  ...                 1                1   \n",
       "\n",
       "      class_numerical  order_numerical  family_numerical genus_numerical  \\\n",
       "0                   0                2                 3               2   \n",
       "1                   0                2                 3               2   \n",
       "2                   0                2                 3               2   \n",
       "3                   0                2                 3               2   \n",
       "4                   0                2                 3               2   \n",
       "...               ...              ...               ...             ...   \n",
       "6744                7               51                78             164   \n",
       "6745                7               51                78             164   \n",
       "6746               11               45               101             163   \n",
       "6747               14               50               111             161   \n",
       "6748                0               32               130             312   \n",
       "\n",
       "     species_numerical img_height img_widgth  \\\n",
       "0                    6        200        300   \n",
       "1                    6        360        300   \n",
       "2                    6        225        300   \n",
       "3                    6        300        300   \n",
       "4                    6        300        300   \n",
       "...                ...        ...        ...   \n",
       "6744               266        225        300   \n",
       "6745               266        240        300   \n",
       "6746               265        169        300   \n",
       "6747               262        200        300   \n",
       "6748               485        400        300   \n",
       "\n",
       "                                                   data  \n",
       "0     b'\\x9b\\x8e\\x85\\x9b\\x8e\\x85\\x9c\\x8f\\x86\\x9c\\x8f...  \n",
       "1     b',3\\x127A\\x1f>L(ET-HT.>D\"36\\x195:#HZDZ|cIz](^...  \n",
       "2     b'O[GbkXip`|\\x80roqfwzq\\xa2\\xa7\\xa0\\x8c\\x96\\x8...  \n",
       "3     b'\\x15\\x12\\x1b\\x12\\x0c\\x16\\x12\\x0c\\x16\\x1a\\x12...  \n",
       "4     b']qoBUS#64\\x1e.-$0.\\x18\"!\\x0b\\x14\\x11\\x10\\x16...  \n",
       "...                                                 ...  \n",
       "6744  b'\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00...  \n",
       "6745  b'\\xe8\\xfd\\xec\\xe9\\xfe\\xed\\xec\\xfe\\xee\\xed\\xff...  \n",
       "6746  b'\\x1a\\x1d\\x08 #\\x0e#&\\x11 #\\x0e\\x1c\\x1f\\n\\x19...  \n",
       "6747  b'\\x11\\r\\x04!\\x18\\x0f\\x16\\x0c\\x02\\r\\x00\\x00\\'\\...  \n",
       "6748  b'!Ku!Ku!Ku!Ku Jt\"It\"Ir\"Ir\\x1fFo\"Gq\"Gq!Gn\"Ho$J...  \n",
       "\n",
       "[6749 rows x 47 columns]"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train, val = train_test_split(full_df, test_size=0.2, stratify=full_df.class_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "_dev_train = pa.Table.from_pandas(train, preserve_index=False)\n",
    "_dev_val = pa.Table.from_pandas(val, preserve_index=False)\n",
    "pq.write_table(_dev_train, \"../data/dev_train.parquet\")\n",
    "pq.write_table(_dev_val, \"../data/dev_val.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fungiclef",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
