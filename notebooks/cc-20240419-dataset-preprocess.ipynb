{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Description\n",
    "The objective of this notebook is to\n",
    "1. Combine both train / val dataset on the dataset page to make one very big dataset\n",
    "2. For classes that are NOT in the train dataset, label them as unknown \n",
    "3. Convert the images to binary file and add it to the dataframe\n",
    "4. Filter for variables in test set only\n",
    "5. Convert all categorical variables (for both input and output) into numerical variables\n",
    "6. Save everything into a parquet\n",
    "\n",
    "This is built on / should replace the work done on images-to-parquet.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "DF20_train_path = \"../data/FungiCLEF2023_train_metadata_PRODUCTION.csv\" # This is the dev training set page\n",
    "DF21_val_path = \"../data/FungiCLEF2023_val_metadata_PRODUCTION.csv\" # This is the \"validation\" set on the page. We want to use this with additional data for unknown classes\n",
    "public_test_path = \"../data/FungiCLEF2023_public_test_metadata_PRODUCTION.csv\" # Public test set\n",
    "IMG_PATH = \"../data/DF\"\n",
    "\n",
    "DF20_df = pd.read_csv(DF20_train_path)\n",
    "DF21_df = pd.read_csv(DF21_val_path)\n",
    "test_df = pd.read_csv(public_test_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_val_df = pd.concat((DF20_df, DF21_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['observationID', 'month', 'day', 'countryCode', 'locality', 'level0Gid',\n",
       "       'level0Name', 'level1Gid', 'level1Name', 'level2Gid', 'level2Name',\n",
       "       'Substrate', 'Latitude', 'Longitude', 'CoorUncert', 'Habitat',\n",
       "       'image_path', 'filename', 'MetaSubstrate'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# These are the metadata we want to keep to train on and potentially for prediction\n",
    "test_df.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['observationID', 'year', 'month', 'day', 'countryCode', 'locality',\n",
       "       'taxonID', 'scientificName', 'kingdom', 'phylum', 'class', 'order',\n",
       "       'family', 'genus', 'specificEpithet', 'taxonRank', 'species',\n",
       "       'level0Gid', 'level0Name', 'level1Gid', 'level1Name', 'level2Gid',\n",
       "       'level2Name', 'ImageUniqueID', 'Substrate', 'rightsHolder', 'Latitude',\n",
       "       'Longitude', 'CoorUncert', 'Habitat', 'image_path', 'class_id',\n",
       "       'MetaSubstrate', 'poisonous', 'filename'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Additionally, we probably want to include all the phylum, genus, etc. It might be useful for additional training data.\n",
    "train_val_df.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_to_keep = list(test_df.keys()) + ['scientificName', 'kingdom', 'phylum', 'class', 'order', 'family', 'genus', 'species', 'poisonous', 'class_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_val_df = train_val_df[cols_to_keep]\n",
    "train_val_df.class_id.max()\n",
    "\n",
    "import numpy as np\n",
    "DUMMY_DATE = 361\n",
    "train_val_df.loc[:, 'normalized_day'] = ((train_val_df['month'] - 1) * 30 + train_val_df['day']).fillna(DUMMY_DATE).astype(np.int16, copy=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make the unknown class the last class instead of -1\n",
    "max_id = train_val_df.class_id.max()\n",
    "train_val_df.loc[:, \"class_id\"] = train_val_df.class_id.apply(lambda x: max_id + 1 if x < 0 else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "categoricals = ['locality', 'level0Gid', 'level1Gid', 'level2Gid', 'Substrate', 'Habitat', 'MetaSubstrate', 'kingdom', 'phylum', 'class',\n",
    "       'order', 'family', 'genus', 'species']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is important to save \n",
    "mapping = {}\n",
    "\n",
    "for col in categoricals:\n",
    "    train_val_df.sort_values(by=col, ascending=True, inplace=True)\n",
    "    col_numerical, col_mapping = pd.factorize(train_val_df[col], use_na_sentinel=True)\n",
    "    train_val_df.loc[:, f\"{col}_numerical\"] = col_numerical\n",
    "    mapping[col] = {v: k for k, v in enumerate(col_mapping)}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "CATEGORICAL_MAPPING_LOCATION = \"../data/categorical_mapping.pkl\"\n",
    "\n",
    "pickle.dump(mapping, open(CATEGORICAL_MAPPING_LOCATION, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This should be converted to a script for submission - categorical mapping for test_df\n",
    "\n",
    "test_categoricals = ['locality', 'level0Gid', 'level1Gid', 'level2Gid', 'Substrate', 'Habitat', 'MetaSubstrate']\n",
    "mapping = pickle.load(open(CATEGORICAL_MAPPING_LOCATION, 'rb'))\n",
    "\n",
    "for col in test_categoricals:\n",
    "    test_df.loc[:, col+\"_numerical\"] = test_df[col].apply(lambda x: mapping[col].get(x, -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_val_df.to_csv(\"train_val_df.csv\", index=False)\n",
    "train_val_df = pd.read_csv(\"train_val_df.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7135/7135 [00:07<00:00, 924.61it/s] \n",
      "100%|██████████| 7135/7135 [00:11<00:00, 599.90it/s]\n",
      "100%|██████████| 7135/7135 [00:11<00:00, 646.25it/s]\n",
      "100%|██████████| 7135/7135 [00:12<00:00, 594.26it/s]\n",
      "100%|██████████| 7135/7135 [00:10<00:00, 664.30it/s]\n",
      "100%|██████████| 7135/7135 [00:11<00:00, 625.52it/s]\n",
      "100%|██████████| 7135/7135 [00:11<00:00, 625.90it/s]\n",
      "100%|██████████| 7135/7135 [00:11<00:00, 616.47it/s]\n",
      "100%|██████████| 7135/7135 [00:11<00:00, 636.19it/s]\n",
      "100%|██████████| 7135/7135 [00:12<00:00, 563.38it/s]\n",
      "100%|██████████| 7135/7135 [00:10<00:00, 655.24it/s]\n",
      "100%|██████████| 7135/7135 [00:11<00:00, 617.87it/s]\n",
      "100%|██████████| 7135/7135 [00:11<00:00, 609.77it/s]\n",
      "100%|██████████| 7135/7135 [00:11<00:00, 613.79it/s]\n",
      "100%|██████████| 7135/7135 [00:11<00:00, 603.92it/s]\n",
      "100%|██████████| 7135/7135 [00:11<00:00, 605.97it/s]\n",
      "100%|██████████| 7135/7135 [00:11<00:00, 622.08it/s]\n",
      "100%|██████████| 7135/7135 [00:11<00:00, 606.60it/s]\n",
      "100%|██████████| 7135/7135 [00:14<00:00, 479.07it/s]\n",
      "100%|██████████| 7135/7135 [00:13<00:00, 524.59it/s]\n",
      "100%|██████████| 7135/7135 [00:11<00:00, 604.21it/s]\n",
      "100%|██████████| 7135/7135 [00:12<00:00, 561.18it/s]\n",
      "100%|██████████| 7135/7135 [00:12<00:00, 582.57it/s]\n",
      "100%|██████████| 7135/7135 [00:13<00:00, 530.48it/s]\n",
      "100%|██████████| 7135/7135 [00:12<00:00, 562.86it/s]\n",
      "100%|██████████| 7135/7135 [00:12<00:00, 587.31it/s]"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# This keeps on crashing + is super inefficient :( \n",
    "# Spark doesn't work on my local machine either\n",
    "# Need to adapt it with images_to_parquet.py stuff\n",
    "\n",
    "import pyarrow as pa\n",
    "import pyarrow.parquet as pq\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "\n",
    "IMG_DIR = \"../data/DF/\"\n",
    "\n",
    "df_records = train_val_df.to_dict(\"records\")\n",
    "CHUNKS = 50\n",
    "CHUNK_SIZE = len(df_records) // CHUNKS\n",
    "\n",
    "for i in range(CHUNKS):\n",
    "    records = []\n",
    "    if i == CHUNKS - 1: \n",
    "        chunk = df_records[i * CHUNK_SIZE:]\n",
    "    else: \n",
    "        chunk = df_records[i * CHUNK_SIZE:(i+1) *CHUNK_SIZE]\n",
    "    for r in tqdm(chunk):\n",
    "        img_name = r['image_path']\n",
    "        if len(img_name.split(\"-\")[0]) == 10:\n",
    "\n",
    "            image_path = IMG_DIR + img_name.replace(\"JPG\", \"jpg\")\n",
    "        else: \n",
    "            image_path = IMG_DIR + img_name\n",
    "        with Image.open(image_path) as im:\n",
    "            r.update({\n",
    "                \"img_height\": im.height,\n",
    "                \"img_widgth\": im.width,\n",
    "                \"data\": im.tobytes()\n",
    "            })\n",
    "        records.append(r)\n",
    "\n",
    "    full_df = pd.DataFrame(records)\n",
    "\n",
    "    _dataset_chunk = pa.Table.from_pandas(full_df, preserve_index=False)\n",
    "    pq.write_table(_dataset_chunk, f\"../data/DF_300_{i}.parquet\") # TODO: To change endpoints where these parquets are stored. But we're using spark anywayz lmao"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "### This is for the dev set only because the full thing keeps on crashing for me :(\n",
    "selected_mushrooms = ['Neoboletus luridiformis (Rostk.) Gelardi, Simonini & Vizzini, 2014',\n",
    "                      'Imleria badia (Fr.) Vizzini, 2014',\n",
    "                      'Amanita muscaria (L.) Lam., 1783',\n",
    "                      'Russula ochroleuca (Pers.) Fr.',\n",
    "                      'Russula nigricans (Bull.) Fr.',\n",
    "                      'Lactarius blennius (Fr.) Fr.'\n",
    "                      ]\n",
    "\n",
    "dev_set = train_val_df.scientificName.isin(selected_mushrooms)\n",
    "\n",
    "dev_df = pd.concat((train_val_df[dev_set], train_val_df[train_val_df.class_id==1604].sample(1000)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in categoricals:\n",
    "    dev_df.sort_values(by=col, ascending=True, inplace=True)\n",
    "    col_numerical, col_mapping = pd.factorize(dev_df[col], use_na_sentinel=True)\n",
    "    dev_df.loc[:, f\"{col}_numerical\"] = col_numerical\n",
    "\n",
    "# Need to do it for class_id too for dev set\n",
    "dev_df.sort_values(by=\"class_id\", ascending=True, inplace=True)\n",
    "numerical, mapping = pd.factorize(dev_df.class_id)\n",
    "dev_df.loc[:, f\"class_id\"] = numerical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "class_id\n",
       "6    1000\n",
       "0     959\n",
       "3     938\n",
       "1     925\n",
       "5     709\n",
       "2     648\n",
       "4     567\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dev_df.class_id.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5746/5746 [00:09<00:00, 600.62it/s]\n"
     ]
    }
   ],
   "source": [
    "# This keeps on crashing + is super inefficient :( \n",
    "# Spark doesn't work on my local machine either\n",
    "# Need to adapt it with images_to_parquet.py stuff\n",
    "\n",
    "import pyarrow as pa\n",
    "import pyarrow.parquet as pq\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "\n",
    "IMG_DIR = \"../data/DF/\"\n",
    "\n",
    "df_records = dev_df.to_dict(\"records\")\n",
    "\n",
    "records = []\n",
    "\n",
    "for r in tqdm(df_records):\n",
    "    img_name = r['image_path']\n",
    "    if len(img_name.split(\"-\")[0]) == 10:\n",
    "\n",
    "        image_path = IMG_DIR + img_name.replace(\"JPG\", \"jpg\")\n",
    "    else: \n",
    "        image_path = IMG_DIR + img_name\n",
    "    with Image.open(image_path) as im:\n",
    "        r.update({\n",
    "            \"img_height\": im.height,\n",
    "            \"img_widgth\": im.width,\n",
    "            \"data\": im.tobytes()\n",
    "        })\n",
    "    records.append(r)\n",
    "\n",
    "full_df = pd.DataFrame(records)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>observationID</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>countryCode</th>\n",
       "      <th>locality</th>\n",
       "      <th>level0Gid</th>\n",
       "      <th>level0Name</th>\n",
       "      <th>level1Gid</th>\n",
       "      <th>level1Name</th>\n",
       "      <th>level2Gid</th>\n",
       "      <th>...</th>\n",
       "      <th>kingdom_numerical</th>\n",
       "      <th>phylum_numerical</th>\n",
       "      <th>class_numerical</th>\n",
       "      <th>order_numerical</th>\n",
       "      <th>family_numerical</th>\n",
       "      <th>genus_numerical</th>\n",
       "      <th>species_numerical</th>\n",
       "      <th>img_height</th>\n",
       "      <th>img_widgth</th>\n",
       "      <th>data</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2856922310</td>\n",
       "      <td>10.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>DK</td>\n",
       "      <td>Slagslunde Skov</td>\n",
       "      <td>DNK</td>\n",
       "      <td>Denmark</td>\n",
       "      <td>DNK.1_1</td>\n",
       "      <td>Hovedstaden</td>\n",
       "      <td>DNK.1.8_1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>225</td>\n",
       "      <td>300</td>\n",
       "      <td>b',G&gt;+I?-KA.LB/MC.LB.LB,LA/OD/OD0PE1RG1RG2SH2S...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2238476158</td>\n",
       "      <td>9.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>DK</td>\n",
       "      <td>Bøtø Plantage</td>\n",
       "      <td>DNK</td>\n",
       "      <td>Denmark</td>\n",
       "      <td>DNK.4_1</td>\n",
       "      <td>Sjælland</td>\n",
       "      <td>DNK.4.3_1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>200</td>\n",
       "      <td>300</td>\n",
       "      <td>b'\\x96\\x86J\\x9a\\x8cO\\xab\\x9ca\\x83w;aU\\x19_U\\x1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2238480549</td>\n",
       "      <td>11.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>DK</td>\n",
       "      <td>Gribskov, Kagerup Station</td>\n",
       "      <td>DNK</td>\n",
       "      <td>Denmark</td>\n",
       "      <td>DNK.1_1</td>\n",
       "      <td>Hovedstaden</td>\n",
       "      <td>DNK.1.16_1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>533</td>\n",
       "      <td>300</td>\n",
       "      <td>b'\\x1dUdBy~C{p:qR(^-\\x17I\\x0e%S\\x15\\x19B\\n D\\x...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2238359812</td>\n",
       "      <td>11.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>DK</td>\n",
       "      <td>Gjorslev Bøgeskov</td>\n",
       "      <td>DNK</td>\n",
       "      <td>Denmark</td>\n",
       "      <td>DNK.4_1</td>\n",
       "      <td>Sjælland</td>\n",
       "      <td>DNK.4.16_1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>225</td>\n",
       "      <td>300</td>\n",
       "      <td>b'C\"\\x19:\\x1a\\x0fF&amp;\\x1bJ,!S5*L0$1\\x15\\t9\\x1e\\x...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2238034375</td>\n",
       "      <td>7.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>DK</td>\n",
       "      <td>Gatten Plantage</td>\n",
       "      <td>DNK</td>\n",
       "      <td>Denmark</td>\n",
       "      <td>DNK.3_1</td>\n",
       "      <td>Nordjylland</td>\n",
       "      <td>DNK.3.11_1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>238</td>\n",
       "      <td>300</td>\n",
       "      <td>b'^UNmd]XQK\\x1d\\x18\\x12$!\\x1a\\x01\\x01\\x00\\x19\\...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5741</th>\n",
       "      <td>3126942337</td>\n",
       "      <td>6.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>DK</td>\n",
       "      <td>Engene</td>\n",
       "      <td>DNK</td>\n",
       "      <td>Denmark</td>\n",
       "      <td>DNK.5_1</td>\n",
       "      <td>Syddanmark</td>\n",
       "      <td>DNK.5.18_1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>46</td>\n",
       "      <td>105</td>\n",
       "      <td>144</td>\n",
       "      <td>240</td>\n",
       "      <td>237</td>\n",
       "      <td>300</td>\n",
       "      <td>b'\\x16\\x1a\\x0b\\x15\\x19\\n\\x13\\x17\\t\\x12\\x16\\x08...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5742</th>\n",
       "      <td>3131207321</td>\n",
       "      <td>6.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>DK</td>\n",
       "      <td>Bagholt Mose (Munkeskov)</td>\n",
       "      <td>DNK</td>\n",
       "      <td>Denmark</td>\n",
       "      <td>DNK.4_1</td>\n",
       "      <td>Sjælland</td>\n",
       "      <td>DNK.4.1_1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>46</td>\n",
       "      <td>105</td>\n",
       "      <td>144</td>\n",
       "      <td>240</td>\n",
       "      <td>400</td>\n",
       "      <td>300</td>\n",
       "      <td>b'\\x9c\\xa4N\\x8f\\x97D\\x8e\\x96I}\\x87B~\\x88L\\xa2\\...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5743</th>\n",
       "      <td>3113023333</td>\n",
       "      <td>5.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>DK</td>\n",
       "      <td>Pinseskoven, Vestamager</td>\n",
       "      <td>DNK</td>\n",
       "      <td>Denmark</td>\n",
       "      <td>DNK.1_1</td>\n",
       "      <td>Hovedstaden</td>\n",
       "      <td>DNK.1.29_1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>46</td>\n",
       "      <td>105</td>\n",
       "      <td>144</td>\n",
       "      <td>240</td>\n",
       "      <td>238</td>\n",
       "      <td>300</td>\n",
       "      <td>b'\\xa3\\x93q\\xa1\\x91o\\xbe\\xab\\x8a\\xa0\\x8ck\\x97\\...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5744</th>\n",
       "      <td>3122828340</td>\n",
       "      <td>5.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>DK</td>\n",
       "      <td>Klosterhede Plantage</td>\n",
       "      <td>DNK</td>\n",
       "      <td>Denmark</td>\n",
       "      <td>DNK.2_1</td>\n",
       "      <td>Midtjylland</td>\n",
       "      <td>DNK.2.8_1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>46</td>\n",
       "      <td>105</td>\n",
       "      <td>144</td>\n",
       "      <td>240</td>\n",
       "      <td>400</td>\n",
       "      <td>300</td>\n",
       "      <td>b'kx\\x81mz\\x83p}\\x86t\\x81\\x8aw\\x84\\x8dy\\x86\\x8...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5745</th>\n",
       "      <td>3131219325</td>\n",
       "      <td>6.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>DK</td>\n",
       "      <td>Kirkeby Hedeskov</td>\n",
       "      <td>DNK</td>\n",
       "      <td>Denmark</td>\n",
       "      <td>DNK.5_1</td>\n",
       "      <td>Syddanmark</td>\n",
       "      <td>DNK.5.18_1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>29</td>\n",
       "      <td>120</td>\n",
       "      <td>307</td>\n",
       "      <td>461</td>\n",
       "      <td>200</td>\n",
       "      <td>300</td>\n",
       "      <td>b'\\x91\\x91\\x93\\x88\\x88\\x8azzzdcaJFE841A&lt;8SNJ\\\\...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5746 rows × 47 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      observationID  month   day countryCode                   locality  \\\n",
       "0        2856922310   10.0   6.0          DK            Slagslunde Skov   \n",
       "1        2238476158    9.0  26.0          DK              Bøtø Plantage   \n",
       "2        2238480549   11.0   1.0          DK  Gribskov, Kagerup Station   \n",
       "3        2238359812   11.0  30.0          DK          Gjorslev Bøgeskov   \n",
       "4        2238034375    7.0  25.0          DK            Gatten Plantage   \n",
       "...             ...    ...   ...         ...                        ...   \n",
       "5741     3126942337    6.0   4.0          DK                     Engene   \n",
       "5742     3131207321    6.0  10.0          DK   Bagholt Mose (Munkeskov)   \n",
       "5743     3113023333    5.0  14.0          DK    Pinseskoven, Vestamager   \n",
       "5744     3122828340    5.0  27.0          DK       Klosterhede Plantage   \n",
       "5745     3131219325    6.0  13.0          DK           Kirkeby Hedeskov   \n",
       "\n",
       "     level0Gid level0Name level1Gid   level1Name   level2Gid  ...  \\\n",
       "0          DNK    Denmark   DNK.1_1  Hovedstaden   DNK.1.8_1  ...   \n",
       "1          DNK    Denmark   DNK.4_1     Sjælland   DNK.4.3_1  ...   \n",
       "2          DNK    Denmark   DNK.1_1  Hovedstaden  DNK.1.16_1  ...   \n",
       "3          DNK    Denmark   DNK.4_1     Sjælland  DNK.4.16_1  ...   \n",
       "4          DNK    Denmark   DNK.3_1  Nordjylland  DNK.3.11_1  ...   \n",
       "...        ...        ...       ...          ...         ...  ...   \n",
       "5741       DNK    Denmark   DNK.5_1   Syddanmark  DNK.5.18_1  ...   \n",
       "5742       DNK    Denmark   DNK.4_1     Sjælland   DNK.4.1_1  ...   \n",
       "5743       DNK    Denmark   DNK.1_1  Hovedstaden  DNK.1.29_1  ...   \n",
       "5744       DNK    Denmark   DNK.2_1  Midtjylland   DNK.2.8_1  ...   \n",
       "5745       DNK    Denmark   DNK.5_1   Syddanmark  DNK.5.18_1  ...   \n",
       "\n",
       "     kingdom_numerical phylum_numerical  class_numerical  order_numerical  \\\n",
       "0                    1                2                0                1   \n",
       "1                    1                2                0                1   \n",
       "2                    1                2                0                1   \n",
       "3                    1                2                0                1   \n",
       "4                    1                2                0                1   \n",
       "...                ...              ...              ...              ...   \n",
       "5741                 1                2                0               46   \n",
       "5742                 1                2                0               46   \n",
       "5743                 1                2                0               46   \n",
       "5744                 1                2                0               46   \n",
       "5745                 1                2                0               29   \n",
       "\n",
       "      family_numerical genus_numerical species_numerical img_height  \\\n",
       "0                    4               3                 6        225   \n",
       "1                    4               3                 6        200   \n",
       "2                    4               3                 6        533   \n",
       "3                    4               3                 6        225   \n",
       "4                    4               3                 6        238   \n",
       "...                ...             ...               ...        ...   \n",
       "5741               105             144               240        237   \n",
       "5742               105             144               240        400   \n",
       "5743               105             144               240        238   \n",
       "5744               105             144               240        400   \n",
       "5745               120             307               461        200   \n",
       "\n",
       "     img_widgth                                               data  \n",
       "0           300  b',G>+I?-KA.LB/MC.LB.LB,LA/OD/OD0PE1RG1RG2SH2S...  \n",
       "1           300  b'\\x96\\x86J\\x9a\\x8cO\\xab\\x9ca\\x83w;aU\\x19_U\\x1...  \n",
       "2           300  b'\\x1dUdBy~C{p:qR(^-\\x17I\\x0e%S\\x15\\x19B\\n D\\x...  \n",
       "3           300  b'C\"\\x19:\\x1a\\x0fF&\\x1bJ,!S5*L0$1\\x15\\t9\\x1e\\x...  \n",
       "4           300  b'^UNmd]XQK\\x1d\\x18\\x12$!\\x1a\\x01\\x01\\x00\\x19\\...  \n",
       "...         ...                                                ...  \n",
       "5741        300  b'\\x16\\x1a\\x0b\\x15\\x19\\n\\x13\\x17\\t\\x12\\x16\\x08...  \n",
       "5742        300  b'\\x9c\\xa4N\\x8f\\x97D\\x8e\\x96I}\\x87B~\\x88L\\xa2\\...  \n",
       "5743        300  b'\\xa3\\x93q\\xa1\\x91o\\xbe\\xab\\x8a\\xa0\\x8ck\\x97\\...  \n",
       "5744        300  b'kx\\x81mz\\x83p}\\x86t\\x81\\x8aw\\x84\\x8dy\\x86\\x8...  \n",
       "5745        300  b'\\x91\\x91\\x93\\x88\\x88\\x8azzzdcaJFE841A<8SNJ\\\\...  \n",
       "\n",
       "[5746 rows x 47 columns]"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train, val = train_test_split(full_df, test_size=0.2, stratify=full_df.class_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "_dev_train = pa.Table.from_pandas(train, preserve_index=False)\n",
    "_dev_val = pa.Table.from_pandas(val, preserve_index=False)\n",
    "pq.write_table(_dev_train, \"../data/dev_train.parquet\")\n",
    "pq.write_table(_dev_val, \"../data/dev_val.parquet\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fungiclef",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
