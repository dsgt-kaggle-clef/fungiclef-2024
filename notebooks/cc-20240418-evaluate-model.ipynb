{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fungiclef.evaluate import predict, evaluate\n",
    "from fungiclef.model.utils import get_timm_model\n",
    "from torch.utils.data import DataLoader, Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import timm\n",
    "import torch.nn as nn\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variables to file path - to edit / change as necessary\n",
    "VAL_PARQUET = \"../dev_val.parquet\"\n",
    "DF20_PRETRAINED = \"../DF20-ViT_large_patch16_224_best_accuracy.pth\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Extract ground truth class IDs\n",
    "val_df = pd.read_parquet(VAL_PARQUET)\n",
    "val_df[['observationID', 'class_id']].drop_duplicates(\"observationID\").to_csv(\"../tmp/gt_id.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example - Using pretrained weights from DF20 team"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_NAME = 'vit_large_patch16_224'\n",
    "model = get_timm_model(MODEL_NAME, 1604, pretrained=False)\n",
    "\n",
    "weights = torch.load(DF20_PRETRAINED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_weights = {k.replace(\"module.\", \"\"): v for k, v in weights.items()}\n",
    "model.load_state_dict(n_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating DataLoader.\n",
      "Running inference.\n",
      "Using device: cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30/30 [00:03<00:00,  8.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving predictions to '../tmp/pred_id.csv'.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "PRED_OUTPUT = \"../tmp/pred_id.csv\"\n",
    "model.eval()\n",
    "predict.run_inference_vit(val_df, PRED_OUTPUT, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluated scores: {'F1 Score': 1.66, 'Track 1: Classification Error': 0.6285, 'Track 2: Cost for Poisonousness Confusion': 11.8283, 'Track 3: User-Focused Loss': 12.4568, 'Track 4: Classification Error with Special Cost for Unknown': 0.6285}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'test_split': {'F1 Score': 1.66,\n",
       "   'Track 1: Classification Error': 0.6285,\n",
       "   'Track 2: Cost for Poisonousness Confusion': 11.8283,\n",
       "   'Track 3: User-Focused Loss': 12.4568,\n",
       "   'Track 4: Classification Error with Special Cost for Unknown': 0.6285}}]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This is a direct port of the official evaluate function the team will be using\n",
    "evaluate.evaluate_csv(test_annotation_file=\"../tmp/gt_id.csv\", user_submission_file=\"../tmp/pred_id.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fungiclef",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
