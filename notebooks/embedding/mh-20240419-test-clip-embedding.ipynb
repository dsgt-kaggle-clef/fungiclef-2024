{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/maximilianheil/fungiclef-2024\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/IPython/core/magics/osm.py:417: UserWarning: using dhist requires you to install the `pickleshare` library.\n",
      "  self.shell.db['dhist'] = compress_dhist(dhist)[-100:]\n"
     ]
    }
   ],
   "source": [
    "%cd /home/maximilianheil/fungiclef-2024/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.types import StringType\n",
    "import pyspark.sql.functions as f\n",
    "import pyspark.ml as ml\n",
    "from pyspark.ml.feature import Tokenizer\n",
    "import fungiclef.embedding.transforms as trans\n",
    "from fungiclef.utils import get_spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "24/04/21 15:12:21 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "24/04/21 15:12:21 WARN SparkConf: Note that spark.local.dir will be overridden by the value set by the cluster manager (via SPARK_LOCAL_DIRS in mesos/standalone/kubernetes and LOCAL_DIRS in YARN).\n",
      "24/04/21 15:12:23 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://fungiclef-dev.us-central1-a.c.dsgt-clef-2024.internal:4041\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.5.1</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[4]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>fungi_clef</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x743e0fbbbd00>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "spark = get_spark(**{\n",
    "    \"spark.sql.parquet.enableVectorizedReader\": False, \n",
    "})\n",
    "display(spark)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- image_path: string (nullable = true)\n",
      " |-- data: binary (nullable = true)\n",
      " |-- observationID: long (nullable = true)\n",
      " |-- year: double (nullable = true)\n",
      " |-- month: double (nullable = true)\n",
      " |-- day: double (nullable = true)\n",
      " |-- countryCode: string (nullable = true)\n",
      " |-- locality: string (nullable = true)\n",
      " |-- taxonID: double (nullable = true)\n",
      " |-- scientificName: string (nullable = true)\n",
      " |-- kingdom: string (nullable = true)\n",
      " |-- phylum: string (nullable = true)\n",
      " |-- class: string (nullable = true)\n",
      " |-- order: string (nullable = true)\n",
      " |-- family: string (nullable = true)\n",
      " |-- genus: string (nullable = true)\n",
      " |-- specificEpithet: string (nullable = true)\n",
      " |-- taxonRank: string (nullable = true)\n",
      " |-- species: string (nullable = true)\n",
      " |-- level0Gid: string (nullable = true)\n",
      " |-- level0Name: string (nullable = true)\n",
      " |-- level1Gid: string (nullable = true)\n",
      " |-- level1Name: string (nullable = true)\n",
      " |-- level2Gid: string (nullable = true)\n",
      " |-- level2Name: string (nullable = true)\n",
      " |-- ImageUniqueID: string (nullable = true)\n",
      " |-- Substrate: string (nullable = true)\n",
      " |-- rightsHolder: string (nullable = true)\n",
      " |-- Latitude: double (nullable = true)\n",
      " |-- Longitude: double (nullable = true)\n",
      " |-- CoorUncert: double (nullable = true)\n",
      " |-- Habitat: string (nullable = true)\n",
      " |-- class_id: integer (nullable = true)\n",
      " |-- MetaSubstrate: string (nullable = true)\n",
      " |-- poisonous: integer (nullable = true)\n",
      " |-- filename: string (nullable = true)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "3686"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "gcs_parquet_path = \"gs://dsgt-clef-fungiclef-2024/dev/dev_train/\"\n",
    "\n",
    "#gcs_parquet_path = \"gs://dsgt-clef-fungiclef-2024/data/parquet/\"\n",
    "#input_folder = f\"DF20\"\n",
    "\n",
    "\n",
    "\n",
    "dev_df = spark.read.parquet(gcs_parquet_path)\n",
    "dev_df.printSchema()\n",
    "dev_df.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transform number to txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cast_floats_to_int(df, list_of_cols):\n",
    "    for col in list_of_cols:\n",
    "        df = df.withColumn(col, dev_df[col].cast('int'))\n",
    "    return df\n",
    "\n",
    "numbers_to_mont_dict = {\n",
    "    1 : \"January\",\n",
    "    2 : \"February\",\n",
    "    3 : \"March\",\n",
    "    4 : \"April\",\n",
    "    5 : \"May\",\n",
    "    6 : \"June\",\n",
    "    7 : \"July\",\n",
    "    8 : \"August\",\n",
    "    9 : \"September\",\n",
    "    10 : \"October\",\n",
    "    11 : \"November\",\n",
    "    12 : \"December\"\n",
    "}\n",
    "\n",
    "def cast_int_to_nl_txt(mapping):\n",
    "    def translate_(col):\n",
    "        return mapping.get(col)\n",
    "    return f.udf(translate_, StringType())\n",
    "\n",
    "dev_df = cast_floats_to_int(dev_df, ['month'])\n",
    "dev_df = dev_df.withColumn('month', cast_int_to_nl_txt(numbers_to_mont_dict)(dev_df['month']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Natural Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['month',\n",
       " 'locality',\n",
       " 'scientificName',\n",
       " 'order',\n",
       " 'family',\n",
       " 'genus',\n",
       " 'specificEpithet',\n",
       " 'species',\n",
       " 'level1Name',\n",
       " 'level2Name',\n",
       " 'Substrate',\n",
       " 'Habitat',\n",
       " 'MetaSubstrate',\n",
       " 'poisonous',\n",
       " 'filename']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ignore_cols = ['class', 'phylum', 'Latitude', 'Longitude', 'CoorUncert', 'txt_data', 'taxonRank', 'class_id', 'kingdom', 'image_path', 'data', 'observationID', 'year', 'ImageUniqueID', 'rightsHolder', 'day', 'countryCode', 'taxonID', 'level0Gid', 'level0Name', 'level1Gid', 'level2Gid']\n",
    "relevant_columns = [col for col in  dev_df.columns if col not in ignore_cols]\n",
    "relevant_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-RECORD 0------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      " txt_data | month August, locality Tofte Skov, scientificName Russula ochroleuca (Pers.) Fr., order Russulales, family Russulaceae, genus Russula, specificEpithet ochroleuca, species Russula ochroleuca, level1Name Nordjylland, level2Name Mariagerfjord, Substrate soil, Habitat Mixed woodland (with coniferous and deciduous trees), MetaSubstrate jord, poisonous 0 \n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# concat all txt data in one col txt_data\n",
    "\n",
    "transformed_cols = [f.concat(f.lit(f\"{col_name} \"), f.col(col_name).cast(\"string\")).alias(col_name) for col_name in relevant_columns]\n",
    "\n",
    "dev_df = dev_df.withColumn(\"txt_data\", f.concat_ws(\", \", *transformed_cols))\n",
    "\n",
    "dev_df.select(\"txt_data\").show(1, vertical=True, truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 8:============================================>              (3 + 1) / 4]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+-------------+-------+\n",
      "|           txt_token|            txt_data|len_txt_token|raw_len|\n",
      "+--------------------+--------------------+-------------+-------+\n",
      "|[month, july,, lo...|month July, local...|           47|    411|\n",
      "|[month, september...|month September, ...|           47|    420|\n",
      "|[month, september...|month September, ...|           47|    389|\n",
      "|[month, september...|month September, ...|           47|    416|\n",
      "|[month, september...|month September, ...|           47|    416|\n",
      "|[month, september...|month September, ...|           47|    416|\n",
      "|[month, september...|month September, ...|           47|    389|\n",
      "|[month, july,, lo...|month July, local...|           47|    411|\n",
      "|[month, october,,...|month October, lo...|           47|    412|\n",
      "|[month, october,,...|month October, lo...|           46|    416|\n",
      "+--------------------+--------------------+-------------+-------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "tokenizer = Tokenizer(outputCol=\"txt_token\")\n",
    "tokenizer.setInputCol(\"txt_data\")\n",
    "\n",
    "tokenized_df = tokenizer.transform(dev_df).select('txt_token', 'txt_data')\n",
    "\n",
    "tokenized_df = tokenized_df.withColumn(\"len_txt_token\", f.size(f.col(\"txt_token\")))\n",
    "tokenized_df = tokenized_df.withColumn(\"raw_len\", f.length(f.col(\"txt_data\")))\n",
    "\n",
    "tokenized_df.sort('len_txt_token', ascending=False).show(10, vertical=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "predict_batch_udf() missing 1 required keyword-only argument: 'return_type'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[47], line 11\u001b[0m\n\u001b[1;32m      8\u001b[0m model \u001b[38;5;241m=\u001b[39m pipeline\u001b[38;5;241m.\u001b[39mfit(dev_df)\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m# Apply the model to transform the DF\u001b[39;00m\n\u001b[0;32m---> 11\u001b[0m transformed_df \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdev_df\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mcache()\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/pyspark/ml/base.py:262\u001b[0m, in \u001b[0;36mTransformer.transform\u001b[0;34m(self, dataset, params)\u001b[0m\n\u001b[1;32m    260\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcopy(params)\u001b[38;5;241m.\u001b[39m_transform(dataset)\n\u001b[1;32m    261\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 262\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    263\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    264\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mParams must be a param map but got \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m \u001b[38;5;28mtype\u001b[39m(params))\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/pyspark/ml/pipeline.py:304\u001b[0m, in \u001b[0;36mPipelineModel._transform\u001b[0;34m(self, dataset)\u001b[0m\n\u001b[1;32m    302\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_transform\u001b[39m(\u001b[38;5;28mself\u001b[39m, dataset: DataFrame) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame:\n\u001b[1;32m    303\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstages:\n\u001b[0;32m--> 304\u001b[0m         dataset \u001b[38;5;241m=\u001b[39m \u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    305\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m dataset\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/pyspark/ml/base.py:262\u001b[0m, in \u001b[0;36mTransformer.transform\u001b[0;34m(self, dataset, params)\u001b[0m\n\u001b[1;32m    260\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcopy(params)\u001b[38;5;241m.\u001b[39m_transform(dataset)\n\u001b[1;32m    261\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 262\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    263\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    264\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mParams must be a param map but got \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m \u001b[38;5;28mtype\u001b[39m(params))\n",
      "File \u001b[0;32m~/fungiclef-2024/fungiclef/embedding/transforms.py:277\u001b[0m, in \u001b[0;36mWrappedCLIPV2._transform\u001b[0;34m(self, df)\u001b[0m\n\u001b[1;32m    275\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_transform\u001b[39m(\u001b[38;5;28mself\u001b[39m, df: DataFrame):\n\u001b[0;32m--> 277\u001b[0m     predict_udf \u001b[38;5;241m=\u001b[39m \u001b[43mpredict_batch_udf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_predict_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    279\u001b[0m     df \u001b[38;5;241m=\u001b[39m  df\u001b[38;5;241m.\u001b[39mwithColumn(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgetOutputCol(), predict_udf(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgetInputCols()[\u001b[38;5;241m0\u001b[39m], \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgetInputCols()[\u001b[38;5;241m1\u001b[39m]))\n\u001b[1;32m    280\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m df\u001b[38;5;241m.\u001b[39mwithColumn(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutput_cols[\u001b[38;5;241m0\u001b[39m], df[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgetOutputCol()][\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutput_cols[\u001b[38;5;241m0\u001b[39m]]) \\\n\u001b[1;32m    281\u001b[0m              \u001b[38;5;241m.\u001b[39mwithColumn(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutput_cols[\u001b[38;5;241m1\u001b[39m], df[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgetOutputCol()][\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutput_cols[\u001b[38;5;241m1\u001b[39m]]) \\\n\u001b[1;32m    282\u001b[0m              \u001b[38;5;241m.\u001b[39mwithColumn(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutput_cols[\u001b[38;5;241m2\u001b[39m], df[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgetOutputCol()][\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutput_cols[\u001b[38;5;241m2\u001b[39m]])\n",
      "\u001b[0;31mTypeError\u001b[0m: predict_batch_udf() missing 1 required keyword-only argument: 'return_type'"
     ]
    }
   ],
   "source": [
    "# Init DINOv2 wrapper\n",
    "clip = trans.WrappedCLIPV2(input_cols=[\"data\",\"txt_data\"], output_cols=['image', 'text', 'dot'])\n",
    "\n",
    "# Create Pipeline\n",
    "pipeline = ml.Pipeline(stages=[clip]) #, dctn\n",
    "\n",
    "# Fit pipeline to DF\n",
    "model = pipeline.fit(dev_df)\n",
    "\n",
    "# Apply the model to transform the DF\n",
    "transformed_df = model.transform(dev_df).cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unused or unrecognized kwargs: padding, truncation.==>              (3 + 1) / 4]\n",
      "Unused or unrecognized kwargs: padding, truncation.\n",
      "Unused or unrecognized kwargs: padding, truncation.\n",
      "Unused or unrecognized kwargs: padding, truncation.\n",
      "Unused or unrecognized kwargs: padding, truncation.\n",
      "Unused or unrecognized kwargs: padding, truncation.\n",
      "Unused or unrecognized kwargs: padding, truncation.\n",
      "Unused or unrecognized kwargs: padding, truncation.\n",
      "Unused or unrecognized kwargs: padding, truncation.\n",
      "Unused or unrecognized kwargs: padding, truncation.\n",
      "Unused or unrecognized kwargs: padding, truncation.\n",
      "Unused or unrecognized kwargs: padding, truncation.\n",
      "Unused or unrecognized kwargs: padding, truncation.\n",
      "Unused or unrecognized kwargs: padding, truncation.\n",
      "Unused or unrecognized kwargs: padding, truncation.\n",
      "Unused or unrecognized kwargs: padding, truncation.\n",
      "Unused or unrecognized kwargs: padding, truncation.\n",
      "Unused or unrecognized kwargs: padding, truncation.\n",
      "Unused or unrecognized kwargs: padding, truncation.\n",
      "Unused or unrecognized kwargs: padding, truncation.\n",
      "Unused or unrecognized kwargs: padding, truncation.\n",
      "Unused or unrecognized kwargs: padding, truncation.\n",
      "Unused or unrecognized kwargs: padding, truncation.\n",
      "Unused or unrecognized kwargs: padding, truncation.\n",
      "Unused or unrecognized kwargs: padding, truncation.\n",
      "Unused or unrecognized kwargs: padding, truncation.\n",
      "Unused or unrecognized kwargs: padding, truncation.\n",
      "Unused or unrecognized kwargs: padding, truncation.\n",
      "Unused or unrecognized kwargs: padding, truncation.\n",
      "Unused or unrecognized kwargs: padding, truncation.\n",
      "Unused or unrecognized kwargs: padding, truncation.\n",
      "Unused or unrecognized kwargs: padding, truncation.\n",
      "Unused or unrecognized kwargs: padding, truncation.\n",
      "Unused or unrecognized kwargs: padding, truncation.\n",
      "Unused or unrecognized kwargs: padding, truncation.\n",
      "Unused or unrecognized kwargs: padding, truncation.\n",
      "Unused or unrecognized kwargs: padding, truncation.\n",
      "Unused or unrecognized kwargs: padding, truncation.\n",
      "Unused or unrecognized kwargs: padding, truncation.\n",
      "Unused or unrecognized kwargs: padding, truncation.\n",
      "Unused or unrecognized kwargs: padding, truncation.\n",
      "Unused or unrecognized kwargs: padding, truncation.\n",
      "Unused or unrecognized kwargs: padding, truncation.\n",
      "Unused or unrecognized kwargs: padding, truncation.\n",
      "Unused or unrecognized kwargs: padding, truncation.\n",
      "Unused or unrecognized kwargs: padding, truncation.\n",
      "Unused or unrecognized kwargs: padding, truncation.\n",
      "Unused or unrecognized kwargs: padding, truncation.\n",
      "Unused or unrecognized kwargs: padding, truncation.\n",
      "Unused or unrecognized kwargs: padding, truncation.\n",
      "Unused or unrecognized kwargs: padding, truncation.\n",
      "Unused or unrecognized kwargs: padding, truncation.\n",
      "Unused or unrecognized kwargs: padding, truncation.\n",
      "Unused or unrecognized kwargs: padding, truncation.\n",
      "Unused or unrecognized kwargs: padding, truncation.\n",
      "Unused or unrecognized kwargs: padding, truncation.\n",
      "Unused or unrecognized kwargs: padding, truncation.\n",
      "Unused or unrecognized kwargs: padding, truncation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+--------------------+--------------------+--------------------+--------------------+\n",
      "|    ImageUniqueID|             species|               image|                text|                 dot|\n",
      "+-----------------+--------------------+--------------------+--------------------+--------------------+\n",
      "|2238067012-303186|  Russula ochroleuca|[0.017991642, 0.0...|[-0.010918789, 0....|[0.28513116, 0.30...|\n",
      "|  2238175058-8780|    Amanita muscaria|[-0.002541536, 0....|[7.609477E-4, 0.0...|[0.2675045, 0.299...|\n",
      "| 2238308944-85884|  Russula ochroleuca|[-0.003997852, 0....|[-0.023495277, 0....|[0.3154308, 0.311...|\n",
      "|2238454170-165728|      Russula adusta|[0.022566577, 0.0...|[-0.01159004, -0....|[0.27796984, 0.26...|\n",
      "| 2238500843-23035|       Imleria badia|[0.022290628, 0.0...|[-0.06541335, -0....|[0.29248983, 0.29...|\n",
      "|2238513675-173334|  Lactarius blennius|[0.01703629, 0.05...|[-0.0039188997, 0...|[0.2854126, 0.257...|\n",
      "| 2238527433-27340|  Russula ochroleuca|[0.018639402, 0.0...|[-0.0035288641, 0...|[0.24208266, 0.26...|\n",
      "|2238547520-179222|Neoboletus luridi...|[0.03242651, 0.07...|[0.011596868, 0.0...|[0.2651499, 0.217...|\n",
      "| 2238555758-32651|    Amanita muscaria|[-0.018535675, 0....|[-0.016720328, 0....|[0.2776954, 0.288...|\n",
      "|2238560169-107971|    Amanita muscaria|[-0.011898746, 0....|[-0.025087517, 0....|[0.30274493, 0.31...|\n",
      "+-----------------+--------------------+--------------------+--------------------+--------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "transformed_df.select([\"ImageUniqueID\", \"species\", \"Output.*\"]).show(n=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unused or unrecognized kwargs: padding, truncation.==>              (3 + 1) / 4]\n",
      "Unused or unrecognized kwargs: padding, truncation.\n",
      "Unused or unrecognized kwargs: padding, truncation.\n",
      "Unused or unrecognized kwargs: padding, truncation.\n",
      "Unused or unrecognized kwargs: padding, truncation.\n",
      "Unused or unrecognized kwargs: padding, truncation.\n",
      "Unused or unrecognized kwargs: padding, truncation.\n",
      "Unused or unrecognized kwargs: padding, truncation.\n",
      "Unused or unrecognized kwargs: padding, truncation.\n",
      "Unused or unrecognized kwargs: padding, truncation.\n",
      "Unused or unrecognized kwargs: padding, truncation.\n",
      "Unused or unrecognized kwargs: padding, truncation.\n",
      "Unused or unrecognized kwargs: padding, truncation.\n",
      "Unused or unrecognized kwargs: padding, truncation.\n",
      "Unused or unrecognized kwargs: padding, truncation.\n",
      "Unused or unrecognized kwargs: padding, truncation.\n",
      "Unused or unrecognized kwargs: padding, truncation.\n",
      "Unused or unrecognized kwargs: padding, truncation.\n",
      "Unused or unrecognized kwargs: padding, truncation.\n",
      "Unused or unrecognized kwargs: padding, truncation.\n",
      "Unused or unrecognized kwargs: padding, truncation.\n",
      "Unused or unrecognized kwargs: padding, truncation.\n",
      "Unused or unrecognized kwargs: padding, truncation.\n",
      "Unused or unrecognized kwargs: padding, truncation.\n",
      "Unused or unrecognized kwargs: padding, truncation.\n",
      "Unused or unrecognized kwargs: padding, truncation.\n",
      "Unused or unrecognized kwargs: padding, truncation.\n",
      "Unused or unrecognized kwargs: padding, truncation.\n",
      "Unused or unrecognized kwargs: padding, truncation.\n",
      "Unused or unrecognized kwargs: padding, truncation.\n",
      "Unused or unrecognized kwargs: padding, truncation.\n",
      "Unused or unrecognized kwargs: padding, truncation.\n",
      "Unused or unrecognized kwargs: padding, truncation.\n",
      "Unused or unrecognized kwargs: padding, truncation.\n",
      "Unused or unrecognized kwargs: padding, truncation.\n",
      "Unused or unrecognized kwargs: padding, truncation.\n",
      "Unused or unrecognized kwargs: padding, truncation.\n",
      "Unused or unrecognized kwargs: padding, truncation.\n",
      "Unused or unrecognized kwargs: padding, truncation.\n",
      "Unused or unrecognized kwargs: padding, truncation.\n",
      "Unused or unrecognized kwargs: padding, truncation.\n",
      "Unused or unrecognized kwargs: padding, truncation.\n",
      "Unused or unrecognized kwargs: padding, truncation.\n",
      "Unused or unrecognized kwargs: padding, truncation.\n",
      "Unused or unrecognized kwargs: padding, truncation.\n",
      "Unused or unrecognized kwargs: padding, truncation.\n",
      "Unused or unrecognized kwargs: padding, truncation.\n",
      "Unused or unrecognized kwargs: padding, truncation.\n",
      "Unused or unrecognized kwargs: padding, truncation.\n",
      "Unused or unrecognized kwargs: padding, truncation.\n",
      "Unused or unrecognized kwargs: padding, truncation.\n",
      "Unused or unrecognized kwargs: padding, truncation.\n",
      "Unused or unrecognized kwargs: padding, truncation.\n",
      "Unused or unrecognized kwargs: padding, truncation.\n",
      "Unused or unrecognized kwargs: padding, truncation.\n",
      "Unused or unrecognized kwargs: padding, truncation.\n",
      "Unused or unrecognized kwargs: padding, truncation.\n",
      "Unused or unrecognized kwargs: padding, truncation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+--------------------+--------------------+--------------------+--------------------+\n",
      "|    ImageUniqueID|             species|               image|                text|                 dot|\n",
      "+-----------------+--------------------+--------------------+--------------------+--------------------+\n",
      "|2238067012-303186|  Russula ochroleuca|[0.017991642, 0.0...|[-0.010918789, 0....|[0.28513116, 0.30...|\n",
      "|  2238175058-8780|    Amanita muscaria|[-0.002541536, 0....|[7.609477E-4, 0.0...|[0.2675045, 0.299...|\n",
      "| 2238308944-85884|  Russula ochroleuca|[-0.003997852, 0....|[-0.023495277, 0....|[0.3154308, 0.311...|\n",
      "|2238454170-165728|      Russula adusta|[0.022566577, 0.0...|[-0.01159004, -0....|[0.27796984, 0.26...|\n",
      "| 2238500843-23035|       Imleria badia|[0.022290628, 0.0...|[-0.06541335, -0....|[0.29248983, 0.29...|\n",
      "|2238513675-173334|  Lactarius blennius|[0.01703629, 0.05...|[-0.0039188997, 0...|[0.2854126, 0.257...|\n",
      "| 2238527433-27340|  Russula ochroleuca|[0.018639402, 0.0...|[-0.0035288641, 0...|[0.24208266, 0.26...|\n",
      "|2238547520-179222|Neoboletus luridi...|[0.03242651, 0.07...|[0.011596868, 0.0...|[0.2651499, 0.217...|\n",
      "| 2238555758-32651|    Amanita muscaria|[-0.018535675, 0....|[-0.016720328, 0....|[0.2776954, 0.288...|\n",
      "|2238560169-107971|    Amanita muscaria|[-0.011898746, 0....|[-0.025087517, 0....|[0.30274493, 0.31...|\n",
      "+-----------------+--------------------+--------------------+--------------------+--------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "transformed_df.select([\"ImageUniqueID\", \"species\", \"Output.*\"]).show(n=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+--------------------+--------------------+\n",
      "|    ImageUniqueID|             species|    transformed_data|\n",
      "+-----------------+--------------------+--------------------+\n",
      "| 2237920504-77555|      Russula adusta|[0.009258113, 0.0...|\n",
      "|  2237966683-5021|      Russula adusta|[0.019642368, 0.0...|\n",
      "| 2237968009-79449|      Russula adusta|[0.0032701602, 0....|\n",
      "| 2238149799-82085|Neoboletus luridi...|[-0.0048931465, 0...|\n",
      "|  2238150033-7827|       Imleria badia|[-0.0015484869, 0...|\n",
      "|2238171177-306291|  Lactarius blennius|[0.003171264, 0.0...|\n",
      "| 2238209494-84510|Neoboletus luridi...|[0.022397494, 0.0...|\n",
      "| 2238331048-11804|  Russula ochroleuca|[-0.014820853, 0....|\n",
      "| 2238428423-15997|  Russula ochroleuca|[0.024092644, 0.0...|\n",
      "| 2238455499-91533|  Lactarius blennius|[0.0208195, 0.047...|\n",
      "+-----------------+--------------------+--------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "transformed_df.select([\"ImageUniqueID\", \"species\", \"transformed_data\"]).show(n=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Init Descrite Cosine Transform wrapper\n",
    "dctn = trans.DCTN(input_col=\"transformed_data\", output_col=\"dctn_data\")\n",
    "\n",
    "# Create Pipeline\n",
    "pipeline = ml.Pipeline(stages=[dino, dctn]) #, dctn\n",
    "\n",
    "# Fit pipeline to DF\n",
    "model = pipeline.fit(dev_subset_df)\n",
    "\n",
    "# Apply the model to transform the DF\n",
    "transformed_df = model.transform(dev_subset_df).cache()\n",
    "\n",
    "# Show results\n",
    "transformed_df.select([\"ImageUniqueID\", \"species\", \"transformed_data\"]).show(n=10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
